{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_experiments.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMMs7/Flixh4ZHt8uQ1HKR5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4dab82dcc117471b914c36aa476bfff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_545d9c6357c5404fb71997820164e9c2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9bbbc7ede62e4d58aa50f232d32ce00c",
              "IPY_MODEL_f6d510f4f1d14ea6a05e8492d8c2e25a"
            ]
          }
        },
        "545d9c6357c5404fb71997820164e9c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bbbc7ede62e4d58aa50f232d32ce00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f37a678231c14c29bdbb6e5357fe5012",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_204ca841e3a144419fa22f52624a6cf1"
          }
        },
        "f6d510f4f1d14ea6a05e8492d8c2e25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_745b9816992c495089da55068c27e713",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 29565655.54it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e4a89cde7514ee8837910c409e5a7c5"
          }
        },
        "f37a678231c14c29bdbb6e5357fe5012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "204ca841e3a144419fa22f52624a6cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "745b9816992c495089da55068c27e713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e4a89cde7514ee8837910c409e5a7c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pabloac31/TFG/blob/master/cifar10_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZIrtm8vDL9s",
        "colab_type": "text"
      },
      "source": [
        "**Clone the repository**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6ctRAXTcHH2",
        "colab_type": "code",
        "outputId": "619356aa-4c44-4084-f28d-d42488f23cfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "! git clone https://github.com/pabloac31/TFG.git\n",
        "%cd TFG"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TFG'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 205 (delta 11), reused 6 (delta 3), pack-reused 183\u001b[K\n",
            "Receiving objects: 100% (205/205), 217.22 MiB | 33.15 MiB/s, done.\n",
            "Resolving deltas: 100% (104/104), done.\n",
            "Checking out files: 100% (30/30), done.\n",
            "/content/TFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmR1_uT1ELeN",
        "colab_type": "text"
      },
      "source": [
        "**Using Tensorflow v1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1YD-wgycX9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2032e674-06c2-4391-b5ff-b3dead8580ab"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wThIjzaBEWab",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Qs_zdCcZS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cifar10_models import *\n",
        "from utils import *\n",
        "from adversarial_attacks import *\n",
        "import statistics "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFqYGnBSFMxL",
        "colab_type": "text"
      },
      "source": [
        "**Use CUDA if available for increase speed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ugar45Fcrmo",
        "colab_type": "code",
        "outputId": "5f6b40df-a004-4185-c33b-1fbdaaa41a0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "use_cuda=True\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eLXv5lbGHwx",
        "colab_type": "text"
      },
      "source": [
        "**Create dataloaders**\n",
        "\n",
        "Load CIFAR10 test images as tensors of size NxCxHxW normalized with CIFAR10 mean and std."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8pZ6UNBctah",
        "colab_type": "code",
        "outputId": "bb93fec4-b047-4e3c-e1e1-e3e531de4ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "4dab82dcc117471b914c36aa476bfff6",
            "545d9c6357c5404fb71997820164e9c2",
            "9bbbc7ede62e4d58aa50f232d32ce00c",
            "f6d510f4f1d14ea6a05e8492d8c2e25a",
            "f37a678231c14c29bdbb6e5357fe5012",
            "204ca841e3a144419fa22f52624a6cf1",
            "745b9816992c495089da55068c27e713",
            "8e4a89cde7514ee8837910c409e5a7c5"
          ]
        }
      },
      "source": [
        "test_loader = testloader_cifar10('./data', batch_size=256, shuffle=False)  # Dataloader for testing the model \n",
        "adv_loader = testloader_cifar10('./data', batch_size=1)                    # Dataloader for adversarial attacks\n",
        "univ_loader = testloader_cifar10('./data', batch_size=1, shuffle=False)    # Dataloader for universal attack"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dab82dcc117471b914c36aa476bfff6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7h0dj4BE-U7",
        "colab_type": "text"
      },
      "source": [
        "**Load models pretrained on CIFAR10**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq7UhHCkcpW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet = resnet50(pretrained=True)\n",
        "densenet = densenet169(pretrained=True)\n",
        "mobnet = mobilenet_v2(pretrained=True)\n",
        "iv3 = inception_v3(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HMLdKZWGvKt",
        "colab_type": "text"
      },
      "source": [
        "**Test models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JwdTaCecvpK",
        "colab_type": "code",
        "outputId": "d40c8f54-54dd-4291-c0bd-1eae043d011b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "acc = test_model(mobnet, device, test_loader)\n",
        "print('\\nAccuracy on CIFAR10 test set: ', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:03<00:00, 10.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy on CIFAR10 test set:  0.9299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5-jN371fV32",
        "colab_type": "text"
      },
      "source": [
        "**Set method parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVW-1y_PfhF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_fgsm = {'epsilon': 0.01, 'clip': True}\n",
        "params_deepfool = {'num_classes': 10, 'overshoot': 0.01, 'max_iter': 50, 'p': 2, 'clip': True}\n",
        "params_sparsefool = {'delta': 255, 'lambda_': 3.0, 'max_iter': 50, 'epsilon': 0.02}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4ipPW1fexSV",
        "colab_type": "text"
      },
      "source": [
        "**Test methods**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHUn30pJcyPK",
        "colab_type": "code",
        "outputId": "be87df42-413d-42f9-920d-e03871efaba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "image, label = next(iter(adv_loader))\n",
        "test_method(resnet, device, image, label, method='sparsefool', params=params_sparsefool)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Succesful attack!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Number of iterations needed:  5\n",
            "Number of perturbed pixels:  17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiUyFraoe-Xh",
        "colab_type": "text"
      },
      "source": [
        "**Perform a complete attack and show results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHSVmm2dc0NZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "bc1eec08-bd3e-4817-cafd-737183bb47a1"
      },
      "source": [
        "#params = {'target_label': None, 'iters': 10, 'pop_size': 100, 'verbose': True}\n",
        "\n",
        "adv_examples = attack_model(resnet, device, adv_loader, 'sparsefool', params_sparsefool)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [2:22:55<00:00,  1.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== RESULTS ========\n",
            "Test Accuracy = 3 / 10000 = 0.0003\n",
            "Average confidence = 0.6109\n",
            "Average time = 0.9090\n",
            "Average magnitude of perturbations = 2.4208\n",
            "Model robustness = 0.1869\n",
            "Avg. iters = 4.94\n",
            "Median num. of pixels perturbed =  19.0\n",
            "Average num. of pixels perturbed =  27.773773339122883\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML7lgfRrYFHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cfc8a59-db84-4424-9a44-81fa4a04dcad"
      },
      "source": [
        "adv_examples = attack_model(densenet, device, adv_loader, 'sparsefool', params_sparsefool)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 11%|█         | 1085/10000 [48:52<3:59:24,  1.61s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-ofMESf1V2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" SPARSEFOOL \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "def unravel_index(index, shape):\n",
        "    out = []\n",
        "    for dim in reversed(shape):\n",
        "        out.append(index % dim)\n",
        "        index = index // dim\n",
        "    return tuple(reversed(out))\n",
        "\n",
        "def linear_solver(x_0, normal, boundary_point, lb, ub):\n",
        "  \n",
        "  # Initialize variables\n",
        "  input_shape = x_0.size()\n",
        "  coord_vec = copy.deepcopy(normal)\n",
        "\n",
        "  # Obtain plane normal vector and boundary point\n",
        "  plane_normal = copy.deepcopy(coord_vec).view(-1)\n",
        "  plane_point = copy.deepcopy(boundary_point).view(-1)\n",
        "\n",
        "  x_i = copy.deepcopy(x_0)   # x(0) <- x_0\n",
        "\n",
        "  # \"Linearized\" classifier\n",
        "  f_k = torch.dot(plane_normal, x_0.view(-1) - plane_point)\n",
        "  sign_true = f_k.sign().item()\n",
        "\n",
        "  beta = 0.001 * sign_true\n",
        "  current_sign = sign_true\n",
        "\n",
        "  #print('sign_true', sign_true)\n",
        "\n",
        "  while current_sign == sign_true and coord_vec.nonzero().size()[0] > 0:  # while w^T(x_i - x_B) != 0\n",
        "\n",
        "    # Update f_k\n",
        "    f_k = torch.dot(plane_normal, x_i.view(-1) - plane_point) + beta\n",
        "\n",
        "    # Maximum |w_j|\n",
        "    pert = f_k.abs() / coord_vec.abs().max()\n",
        "\n",
        "    mask = torch.zeros_like(coord_vec)\n",
        "    mask[unravel_index(torch.argmax(coord_vec.abs()), input_shape)] = 1.\n",
        "\n",
        "    # Update r_i\n",
        "    r_i = torch.clamp(pert, min=1e-4) * mask * (-sign_true * coord_vec.sign())  # added -sign_true !!!\n",
        "\n",
        "    # Update perturbation with the desired constraints\n",
        "    x_i = x_i + r_i\n",
        "    x_i = clip_image_values(x_i, lb, ub)\n",
        "\n",
        "    # Update predictions\n",
        "    f_k = torch.dot(plane_normal, x_i.view(-1) - plane_point)\n",
        "    current_sign = f_k.sign().item()\n",
        "\n",
        "    coord_vec[r_i != 0] = 0\n",
        "\n",
        "  return x_i.detach()  # for deepcopy\n",
        "\n",
        "\n",
        "def sparsefool(model, device, x_0, label, lb, ub, lambda_=3., max_iter=20, epsilon=0.02):\n",
        "\n",
        "  # Initialize variables\n",
        "  x_i = copy.deepcopy(x_0)\n",
        "  fool_im = copy.deepcopy(x_i)\n",
        "  fool_label = label\n",
        "  loops = 0\n",
        "\n",
        "  while fool_label == label and loops < max_iter:\n",
        "\n",
        "    # Compute l2 adversarial perturbation (using DeepFool)\n",
        "    normal, x_adv,_,_ = deepfool(model, device, x_i, lambda_fac=lambda_)\n",
        "\n",
        "    # Update x_i using the linear solver\n",
        "    x_i = linear_solver(x_i, normal, x_adv, lb, ub)\n",
        "\n",
        "    # Adding epsilon to compute fool_im\n",
        "    fool_im = x_0 + (1 + epsilon) * (x_i - x_0)\n",
        "    # Clip values using lb, ub\n",
        "    fool_im = clip_image_values(fool_im, lb, ub)\n",
        "    # Obtain current prediction\n",
        "    x = fool_im.clone().detach().requires_grad_(True)\n",
        "    fool_label = torch.argmax(model(x).data).item()\n",
        "\n",
        "    loops += 1\n",
        "\n",
        "  r = fool_im - x_0\n",
        "  return fool_im, r, loops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xseEdeDnHlGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v = universal_perturbation(univ_loader, iv3, device, delta=0.1)\n",
        "\n",
        "plt.imshow(denormalize_cifar10(v[0].cpu().detach().numpy()).transpose((1,2,0)))\n",
        "plt.title('Universal perturbation')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTnsNwRMmxWt",
        "colab_type": "code",
        "outputId": "de85220c-075a-412b-9379-2359bd7132c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "image = Image.open('./data/img1.png')\n",
        "x = TF.to_tensor(image)\n",
        "x = normalize_cifar10(x)\n",
        "x = x.unsqueeze_(0).to(device)\n",
        "label = torch.tensor([1]).to(device)\n",
        "print('Label:', label.item())\n",
        "x.requires_grad = True\n",
        "y = iv3(x)\n",
        "init_pred = y.max(1, keepdim=True)[1]\n",
        "print(\"Original image prediction: \", init_pred.item())\n",
        "x_r = x.add(v).to(device)\n",
        "pred = iv3(x_r).max(1, keepdim=True)[1]\n",
        "print(\"Perturbed image prediction: \", pred.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 1\n",
            "Original image prediction:  1\n",
            "Perturbed image prediction:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoSdwQ1ne1mA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img, label = next(iter(adv_loader))\n",
        "im = denormalize_cifar10(img.numpy()[0].copy()).transpose((1,2,0))\n",
        "plt.imshow(im)\n",
        "plt.show()\n",
        "label = label.item()\n",
        "success, sol, score = one_pixel_attack(iv3, device, img, label, pop_size=400, iters=20)\n",
        "print(success)\n",
        "print(score)\n",
        "adv = perturb(sol, img)\n",
        "im = denormalize_cifar10(adv.numpy()[0].copy()).transpose((1,2,0))\n",
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CU4A8L3KmqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_method(model, device, img, label, method, params):\n",
        "\n",
        "  img = img.clone()\n",
        "\n",
        "  model = model.to(device).eval()\n",
        "\n",
        "  x = img.to(device)\n",
        "  label = label.to(device)\n",
        "\n",
        "  x.requires_grad = True\n",
        "\n",
        "  y = model(x)\n",
        "  init_pred = y.max(1, keepdim=True)[1]\n",
        "  x_conf = F.softmax(y, dim=1).max(1, keepdim=True)[0].item()  \n",
        "\n",
        "  if init_pred.item() != label.item():\n",
        "    print(\"Wrong classification...\")\n",
        "    return\n",
        "\n",
        "  # Call method\n",
        "  if method == 'fgsm':\n",
        "    adv_x, pert_x = fgsm(model, x, label, y, params[\"epsilon\"], params[\"clip\"])\n",
        "\n",
        "  elif method == 'deepfool':\n",
        "    _, adv_x, pert_x, n_iter = deepfool(model, device, x, params[\"num_classes\"], overshoot=params[\"overshoot\"], max_iter=params[\"max_iter\"], p=params[\"p\"], clip=params[\"clip\"])\n",
        "\n",
        "  elif method == 'sparsefool':\n",
        "    # Generate lower and upper bounds\n",
        "    delta = params[\"delta\"]\n",
        "    lb, ub =  valid_bounds(x, delta, dataset='cifar10')\n",
        "    lb = lb[None, :, :, :].to(device)\n",
        "    ub = ub[None, :, :, :].to(device)\n",
        "    adv_x, pert_x, n_iter = sparsefool(model, device, x, label.item(), lb, ub, params[\"lambda_\"], params[\"max_iter\"], params[\"epsilon\"])\n",
        "\n",
        "  elif method == 'one_pixel_attack':\n",
        "    _, best_sol, score = one_pixel_attack(model, device, data, target.item(), params[\"target_label\"], params[\"iters\"], params[\"pop_size\"], params[\"verbose\"])\n",
        "    adv_x = perturb(best_sol, data)\n",
        "\n",
        "  y_adv = model(adv_x)\n",
        "  adv_pred = y_adv.max(1, keepdim=True)[1]\n",
        "  adv_x_conf = F.softmax(y_adv, dim=1).max(1, keepdim=True)[0].item()  \n",
        "\n",
        "  if adv_pred.item() == label.item():\n",
        "    print(\"Attack failed...\")\n",
        "\n",
        "  else:\n",
        "    print(\"Succesful attack!\")\n",
        "\n",
        "  f = plt.figure()\n",
        "  f.add_subplot(1,3,1)\n",
        "  plt.title('Original image')\n",
        "  plt.axis('off')\n",
        "  f.text(.25, .3, cifar10_classes[label.item()] + ' ({:.2f}%)'.format(x_conf*100), ha='center')\n",
        "  plt.imshow(displayable(img))\n",
        "  f.add_subplot(1,3,2)\n",
        "  plt.title('Perturbation')\n",
        "  plt.axis('off')\n",
        "  plt.imshow(displayable(pert_x.cpu().detach()))\n",
        "  f.add_subplot(1,3,3)\n",
        "  plt.title('Adv. image')\n",
        "  plt.axis('off')\n",
        "  f.text(.8, .3, cifar10_classes[adv_pred.item()] + ' ({:.2f}%)'.format(adv_x_conf*100), ha='center')\n",
        "  plt.imshow(displayable(adv_x.cpu().detach()))\n",
        "  plt.show(block=True)\n",
        "\n",
        "  if method in ['deepfool',  'sparsefool']:\n",
        "    print('Number of iterations needed: ', n_iter)\n",
        "\n",
        "  if method == 'sparsefool':\n",
        "    pert_pixels = pert_x.flatten().nonzero().size(0)\n",
        "    print('Number of perturbed pixels: ', pert_pixels) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zxW6hZmQfyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attack_model(model, device, test_loader, method, params, p=2, iters=10000, dataset='cifar10'):\n",
        "\n",
        "  # Initialize the network and set the model in evaluation mode.\n",
        "  model = model.to(device).eval()\n",
        "\n",
        "  # Initialize stat counters\n",
        "  correct = 0\n",
        "  incorrect = 0\n",
        "  confidence = 0\n",
        "  total_time = 0\n",
        "  ex_robustness = 0\n",
        "  model_robustness = 0\n",
        "  method_iters = 0\n",
        "  n_pert_pixels = []\n",
        "  adv_examples = []\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  # Loop (iters) examples in test set\n",
        "  for data, target in pbar(test_loader):\n",
        "    if i >= iters:\n",
        "      break\n",
        "    i += 1\n",
        "\n",
        "    # Send the data and label to the device\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Set requires_grad attribute of tensor (important for some attacks)\n",
        "    if method in ['fgsm', 'deepfool', 'sparsefool']:\n",
        "        data.requires_grad = True\n",
        "\n",
        "    # Forward pass the data through the model\n",
        "    output = model(data)\n",
        "    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "    # If the initial prediction is wrong, dont botter attacking\n",
        "    if init_pred.item() != target.item():\n",
        "      continue\n",
        "\n",
        "    if method == 'fgsm':\n",
        "        # Call FGSM attack\n",
        "        time_ini = time.time()\n",
        "        perturbed_data, _ = fgsm(model, data, target, output, params[\"epsilon\"], params[\"clip\"], dataset)\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "\n",
        "    elif method == 'deepfool':\n",
        "        # Call DeepFool attack\n",
        "        time_ini = time.time()\n",
        "        _, perturbed_data, _, n_iter = deepfool(model, device, data, params[\"num_classes\"], overshoot=params[\"overshoot\"], max_iter=params[\"max_iter\"], p=params[\"p\"], clip=params[\"clip\"])\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "        method_iters += n_iter\n",
        "\n",
        "    elif method == 'sparsefool':\n",
        "        # Generate lower and upper bounds\n",
        "        delta = params[\"delta\"]\n",
        "        lb, ub =  valid_bounds(data, delta, dataset='cifar10')\n",
        "        lb = lb[None, :, :, :].to(device)\n",
        "        ub = ub[None, :, :, :].to(device)\n",
        "        # Call SparseFool attack\n",
        "        time_ini = time.time()\n",
        "        perturbed_data, perturbation, n_iter = sparsefool(model, device, data, target.item(), lb, ub, params[\"lambda_\"], params[\"max_iter\"], params[\"epsilon\"])\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "        method_iters += n_iter\n",
        "        n_pert_pixels.append(perturbation.flatten().nonzero().size(0))\n",
        "\n",
        "    elif method == 'one_pixel_attack':\n",
        "        # Call one pixel attack\n",
        "        time_ini = time.time()\n",
        "        _, best_sol, score = one_pixel_attack(model, device, data, target.item(), params[\"target_label\"], params[\"iters\"], params[\"pop_size\"], params[\"verbose\"])\n",
        "        perturbed_data = perturb(best_sol, data)\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "\n",
        "\n",
        "    # Update model robustness\n",
        "    # multiply by std to make it independent of the normalization used\n",
        "    difference = de_scale(perturbed_data-data, dataset)\n",
        "    if p == 2:\n",
        "      adv_rob = torch.norm(difference)  # Frobenius norm (p=2)\n",
        "      model_robustness += adv_rob / torch.norm(de_scale(data, dataset))\n",
        "    elif p == np.inf:\n",
        "      adv_rob = torch.norm(difference, float('inf'))  # Inf norm (p=inf)\n",
        "      model_robustness += adv_rob / torch.norm(de_scale(data, dataset), float('inf'))\n",
        "    ex_robustness += adv_rob\n",
        "    \n",
        "    # Re-classify the perturbed image\n",
        "    output = model(perturbed_data)\n",
        "\n",
        "    # Check for success\n",
        "    final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "    \n",
        "    if final_pred.item() == target.item():\n",
        "      correct += 1\n",
        "    \n",
        "    else:\n",
        "      incorrect += 1\n",
        "      # Update average confidence\n",
        "      confidence += F.softmax(output, dim=1).max(1, keepdim=True)[0].item()  \n",
        "      # Save some adv examples for visualization later\n",
        "      if len(adv_examples) < 5:\n",
        "        adv_examples.append( (init_pred.item(), final_pred.item(), data.detach().cpu(), perturbed_data.detach().cpu()) )\n",
        "\n",
        "  # Calculate stats\n",
        "  final_acc = correct / float(iters)  # len(test_loader)\n",
        "  avg_confidence = confidence / float(incorrect)\n",
        "  avg_time = total_time / float(correct+incorrect)\n",
        "  avg_ex_robustness = ex_robustness / float(correct+incorrect)\n",
        "  model_robustness = model_robustness / float(correct+incorrect)\n",
        "  print(\"\\n======== RESULTS ========\")\n",
        "  print(\"Test Accuracy = {} / {} = {:.4f}\\nAverage confidence = {:.4f}\\nAverage time = {:.4f}\\nAverage magnitude of perturbations = {:.4f}\\nModel robustness = {:.4f}\"\n",
        "    .format(correct, iters, final_acc, avg_confidence, avg_time, avg_ex_robustness, model_robustness))\n",
        "\n",
        "  if method in ['deepfool', 'sparsefool']:\n",
        "    print(\"Avg. iters = {:.2f}\".format(method_iters / float(correct+incorrect)))\n",
        "\n",
        "  if method == 'sparsefool':\n",
        "    print(\"Median num. of pixels perturbed = \", statistics.median(n_pert_pixels))\n",
        "    print(\"Average num. of pixels perturbed = \", statistics.mean(n_pert_pixels))\n",
        "\n",
        "  # Return adversarial examples\n",
        "  return adv_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-F8_drp9Hur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" DEEPFOOL \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "def deepfool(model, device, im, num_classes=10, overshoot=0.02, lambda_fac=1.01, max_iter=50, p=2, clip=False, dataset='cifar10'):\n",
        "\n",
        "  image = copy.deepcopy(im)\n",
        "\n",
        "  # Get the input image shape\n",
        "  input_shape = image.size()\n",
        "\n",
        "  # Get the output of the original image\n",
        "  output = model(image)\n",
        " \n",
        "  # Array with the class probabilities of the image\n",
        "  f_image = output.data.cpu().numpy().flatten()\n",
        "  # Classes ordered by probability (descending)\n",
        "  I = f_image.argsort()[::-1]\n",
        "  # We consider only 'num_classes' classes\n",
        "  I = I[0:num_classes]\n",
        "\n",
        "  # Get the predicted label\n",
        "  label = I[0]\n",
        "\n",
        "  # Start from a copy of the original image\n",
        "  pert_image = copy.deepcopy(image)   # tensor of size (1,3,H,W)\n",
        "\n",
        "  # Initialize variables\n",
        "  r_tot = torch.zeros(input_shape).to(device) # adversarial perturbation\n",
        "  k_i = label  # current label\n",
        "  loop_i = 0\n",
        "\n",
        "  while k_i == label and loop_i < max_iter:\n",
        "\n",
        "    # Get the output for the current image\n",
        "    x = pert_image.clone().detach().requires_grad_(True)\n",
        "    fs = model(x)\n",
        "\n",
        "    pert = torch.Tensor([np.inf])[0].to(device)\n",
        "    w = torch.zeros(input_shape).to(device)\n",
        "\n",
        "    # Calculate grad(f_label(x_i))\n",
        "    fs[0, I[0]].backward(retain_graph=True)\n",
        "    grad_orig = copy.deepcopy(x.grad.data)\n",
        "\n",
        "    for k in range(1, num_classes):  # for k != label\n",
        "      # Reset gradients\n",
        "      zero_gradients(x)\n",
        "\n",
        "      # Calculate grad(f_k(x_i))\n",
        "      fs[0, I[k]].backward(retain_graph=True)\n",
        "      cur_grad = copy.deepcopy(x.grad.data)\n",
        "\n",
        "      # Set new w_k and new f_k\n",
        "      w_k = cur_grad - grad_orig\n",
        "      f_k = (fs[0, I[k]] - fs[0, I[0]]).data\n",
        "\n",
        "      # Calculate hyperplane-k distance\n",
        "      if p == 2:\n",
        "        pert_k = torch.abs(f_k) / w_k.norm()  # Frobenious norm (2-norm)\n",
        "      elif p == np.inf:\n",
        "        pert_k = torch.abs(f_k) / w_k.norm(1) # 1-norm\n",
        "\n",
        "      # determine which w_k to use\n",
        "      if pert_k < pert:\n",
        "        pert = pert_k + 0.\n",
        "        w = w_k + 0.\n",
        "\n",
        "    # compute r_i and r_tot\n",
        "    if p == 2:\n",
        "      r_i = torch.clamp(pert, min=1e-4) * w / w.norm()  # Added 1e-4 for numerical stability\n",
        "    elif p == np.inf:\n",
        "      r_i = torch.clamp(pert, min=1e-4) * torch.sign(w)\n",
        "\n",
        "    r_tot = r_tot + r_i\n",
        "\n",
        "    # Update perturbed image\n",
        "    pert_image = pert_image + r_i  # x_(i+1) <- x_i + r_i\n",
        "\n",
        "    # Adding overshoot\n",
        "    check_fool = image + (1 + overshoot) * r_tot\n",
        "\n",
        "    x = check_fool.clone().detach().requires_grad_(True)\n",
        "    # output for x_(i+1)\n",
        "    fs = model(x)\n",
        "    # label assigned to x_(i+1)\n",
        "    k_i = torch.argmax(fs.data).item()\n",
        "\n",
        "    loop_i += 1\n",
        "\n",
        "  # Compute final perturbed image output\n",
        "  x = pert_image.clone().detach().requires_grad_(True)\n",
        "  fs = model(x)\n",
        "  # Compute final gradient\n",
        "  (fs[0, k_i] - fs[0, label]).backward(retain_graph=True)\n",
        "  grad = copy.deepcopy(x.grad.data)\n",
        "  grad = grad / grad.norm()\n",
        "\n",
        "  # Include lambda_fac in the adversarial perturbation\n",
        "  r_tot = lambda_fac * r_tot  # for SparseFool\n",
        "\n",
        "  # Adding clipping to maintain [0,1] range\n",
        "  if clip:\n",
        "    pert_image = clamp(image + r_tot, 0, 1, dataset)\n",
        "\n",
        "  else:\n",
        "    pert_image = (image + r_tot).clone().detach()\n",
        "\n",
        "  return grad, pert_image, r_tot, loop_i"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}