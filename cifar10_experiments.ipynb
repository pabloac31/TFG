{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_experiments.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNeH7RLNyREGD8IEmcbOYMX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6fff3b8e4fd7402cb6854f52580acae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ee949047762464cbd92f102eae48661",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed431153ed3e4388a50abd4ae81058fd",
              "IPY_MODEL_243dba882ad14b7b9dd98f4c1b781975"
            ]
          }
        },
        "9ee949047762464cbd92f102eae48661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed431153ed3e4388a50abd4ae81058fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_63eef7288b654975aebb7fd939aa39c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6fa5247dc174c3fa45fc8cfbd3b466f"
          }
        },
        "243dba882ad14b7b9dd98f4c1b781975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_793072c4dda444aca0ae22af5a683b1c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 83152198.74it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c29c2a2d4daa4d4fb0e13647f260d49b"
          }
        },
        "63eef7288b654975aebb7fd939aa39c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6fa5247dc174c3fa45fc8cfbd3b466f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "793072c4dda444aca0ae22af5a683b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c29c2a2d4daa4d4fb0e13647f260d49b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "496493b8a307432aaa6579ed169c36b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5c81e5c0bc8b4923b8bf655e64077998",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_44fad1a5aa3d4fb386f2c728d8be9dd8",
              "IPY_MODEL_790914b746d84991bb3b533b5b2a3585"
            ]
          }
        },
        "5c81e5c0bc8b4923b8bf655e64077998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44fad1a5aa3d4fb386f2c728d8be9dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dcfc7159ff944cacb0b5ab5aa7ad00e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fa1035557854dd380690aacecf07744"
          }
        },
        "790914b746d84991bb3b533b5b2a3585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fea72734a1b64968a615854f345e244a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 32373868.76it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b39567b5cd7342858400d7bc07f1e618"
          }
        },
        "dcfc7159ff944cacb0b5ab5aa7ad00e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fa1035557854dd380690aacecf07744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fea72734a1b64968a615854f345e244a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b39567b5cd7342858400d7bc07f1e618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pabloac31/TFG/blob/master/cifar10_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6ctRAXTcHH2",
        "colab_type": "code",
        "outputId": "849f80b7-1a88-4045-e10f-698d180682ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "! git clone https://github.com/pabloac31/TFG.git\n",
        "%cd TFG"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TFG'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 116 (delta 46), reused 31 (delta 14), pack-reused 41\u001b[K\n",
            "Receiving objects: 100% (116/116), 79.06 MiB | 29.02 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n",
            "/content/TFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1YD-wgycX9P",
        "colab_type": "code",
        "outputId": "c31916e0-168f-4b1f-c940-483d832dc827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK6jHL4ElHxE",
        "colab_type": "code",
        "outputId": "53e1a80a-bd3d-4c22-d834-b1c958b1a26f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! git pull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Qs_zdCcZS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cifar10_models import *\n",
        "from utils import *\n",
        "from adversarial_attacks import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq7UhHCkcpW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iv3 = inception_v3(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ugar45Fcrmo",
        "colab_type": "code",
        "outputId": "4f304bdd-63ce-4430-fc8e-89d05bcc510b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Define what device we are using\n",
        "use_cuda=True\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8pZ6UNBctah",
        "colab_type": "code",
        "outputId": "fdce7c63-7151-4b00-d0cb-8e2c7da700f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "6fff3b8e4fd7402cb6854f52580acae6",
            "9ee949047762464cbd92f102eae48661",
            "ed431153ed3e4388a50abd4ae81058fd",
            "243dba882ad14b7b9dd98f4c1b781975",
            "63eef7288b654975aebb7fd939aa39c9",
            "e6fa5247dc174c3fa45fc8cfbd3b466f",
            "793072c4dda444aca0ae22af5a683b1c",
            "c29c2a2d4daa4d4fb0e13647f260d49b"
          ]
        }
      },
      "source": [
        "test_loader = testloader_cifar10('./data', 256)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fff3b8e4fd7402cb6854f52580acae6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JwdTaCecvpK",
        "colab_type": "code",
        "outputId": "60383166-675f-4056-86ee-90eef84871fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_model(iv3, device, test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:21<00:00,  1.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9541"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28VPsKJXcw4p",
        "colab_type": "code",
        "outputId": "10bd7dfa-5db6-4b24-d0a6-37a47d117a09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "496493b8a307432aaa6579ed169c36b1",
            "5c81e5c0bc8b4923b8bf655e64077998",
            "44fad1a5aa3d4fb386f2c728d8be9dd8",
            "790914b746d84991bb3b533b5b2a3585",
            "dcfc7159ff944cacb0b5ab5aa7ad00e1",
            "5fa1035557854dd380690aacecf07744",
            "fea72734a1b64968a615854f345e244a",
            "b39567b5cd7342858400d7bc07f1e618"
          ]
        }
      },
      "source": [
        "adv_loader = testloader_cifar10('./data', 1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "496493b8a307432aaa6579ed169c36b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHUn30pJcyPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_fgsm(iv3, device, './data/img1.png', 0.56)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVFc-l2l1wj9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "9d3fc979-1b3f-4ef1-a362-041366de4457"
      },
      "source": [
        "mean_cifar10, std_cifar10 = [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "iv3.eval()\n",
        "\n",
        "im_orig = Image.open('./data/img1.png')\n",
        "\n",
        "im = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = mean_cifar10,\n",
        "                         std = std_cifar10)])(im_orig)\n",
        "\n",
        "\n",
        "im = im.to(device)\n",
        "\n",
        "#print(iv3.forward(Variable(im[None,:,:,:], requires_grad=True)))\n",
        "f_image = iv3.forward(Variable(im[None,:,:,:], requires_grad=True)).data.cpu().numpy().flatten()\n",
        "I = (np.array(f_image)).flatten().argsort()[::-1]\n",
        "input_shape = im.cpu().numpy().shape\n",
        "print(input_shape)\n",
        "pert_image = copy.deepcopy(im)\n",
        "w = np.zeros(input_shape)\n",
        "r_tot = np.zeros(input_shape)\n",
        "print(pert_image[None,:].shape)\n",
        "x = Variable(pert_image[None,:], requires_grad=True)\n",
        "fs = iv3.forward(x)\n",
        "print(fs)\n",
        "fs_list = [fs[0,I[k]] for k in range(10)]\n",
        "print(fs_list)\n",
        "\n",
        "imagen = im[None,:,:,:]\n",
        "imagen.requires_grad = True\n",
        "output = iv3(imagen)\n",
        "f_image = output.data.cpu().numpy().flatten()\n",
        "I = f_image.argsort()[::-1]\n",
        "print(imagen.cpu().detach().numpy()[0].shape)\n",
        "pert_image = copy.deepcopy(imagen)\n",
        "w = np.zeros(input_shape)\n",
        "r_tot = np.zeros(input_shape)\n",
        "x = pert_image.clone().detach().requires_grad_(True)\n",
        "fs = iv3(x)\n",
        "print(fs)\n",
        "fs_list = [fs[0,I[k]] for k in range(10)]\n",
        "print(fs_list)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 32, 32)\n",
            "torch.Size([1, 3, 32, 32])\n",
            "tensor([[-0.8157,  7.8002, -1.0493, -1.2021, -1.4486, -1.4926, -0.8814, -1.0291,\n",
            "          0.0151,  0.1035]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "[tensor(7.8002, device='cuda:0', grad_fn=<SelectBackward>), tensor(0.1035, device='cuda:0', grad_fn=<SelectBackward>), tensor(0.0151, device='cuda:0', grad_fn=<SelectBackward>), tensor(-0.8157, device='cuda:0', grad_fn=<SelectBackward>), tensor(-0.8814, device='cuda:0', grad_fn=<SelectBackward>), tensor(-1.0291, device='cuda:0', grad_fn=<SelectBackward>), tensor(-1.0493, device='cuda:0', grad_fn=<SelectBackward>), tensor(-1.2021, device='cuda:0', grad_fn=<SelectBackward>), tensor(-1.4486, device='cuda:0', grad_fn=<SelectBackward>), tensor(-1.4926, device='cuda:0', grad_fn=<SelectBackward>)]\n",
            "(3, 32, 32)\n",
            "tensor([[-0.8157,  7.8002, -1.0493, -1.2021, -1.4486, -1.4926, -0.8814, -1.0291,\n",
            "          0.0151,  0.1035]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "[tensor(7.8002, device='cuda:0', grad_fn=<SelectBackward>), tensor(0.1035, device='cuda:0', grad_fn=<SelectBackward>), tensor(0.0151, device='cuda:0', grad_fn=<SelectBackward>), tensor(-0.8157, device='cuda:0', grad_fn=<SelectBackward>), tensor(-0.8814, device='cuda:0', grad_fn=<SelectBackward>), tensor(-1.0291, device='cuda:0', grad_fn=<SelectBackward>), tensor(-1.0493, device='cuda:0', grad_fn=<SelectBackward>), tensor(-1.2021, device='cuda:0', grad_fn=<SelectBackward>), tensor(-1.4486, device='cuda:0', grad_fn=<SelectBackward>), tensor(-1.4926, device='cuda:0', grad_fn=<SelectBackward>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsGCn9Bl1r4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deepfool(model, device, image, label, output, num_classes=10, overshoot=0.02, max_iter=50):\n",
        "  # Classes ordered by probability (descending)\n",
        "  f_image = output.data.cpu().numpy().flatten()\n",
        "  I = f_image.argsort()[::-1]\n",
        "  I = I[0:num_classes]  # pick only num_classes \n",
        "\n",
        "  # Start from original image (copy)\n",
        "  input_shape = image.cpu().detach().numpy()[0].shape   # (3,H,W)\n",
        "  pert_image = copy.deepcopy(image)   # tensor of size (1,3,H,W)\n",
        "  w = np.zeros(input_shape)\n",
        "  r_tot = np.zeros(input_shape)\n",
        "\n",
        "  loop_i = 0\n",
        "\n",
        "  x = pert_image.clone().detach().requires_grad_(True)\n",
        "  fs = model(x)\n",
        "  k_i = label\n",
        "\n",
        "  while k_i == label and loop_i < max_iter:\n",
        "\n",
        "    pert = np.inf\n",
        "    fs[0, I[0]].backward(retain_graph=True)\n",
        "    grad_orig = x.grad.data.cpu().numpy().copy()\n",
        "\n",
        "    for k in range(1, num_classes):\n",
        "      zero_gradients(x)\n",
        "\n",
        "      fs[0, I[k]].backward(retain_graph=True)\n",
        "      cur_grad = x.grad.data.cpu().numpy().copy()\n",
        "\n",
        "      # set new w_k and new f_k\n",
        "      w_k = cur_grad - grad_orig \n",
        "      f_k = (fs[0, I[k]] - fs[0, I[0]]).data.cpu().numpy()\n",
        "      \n",
        "      pert_k = abs(f_k)/np.linalg.norm(w_k.flatten())\n",
        "\n",
        "      # determine which w_k to use\n",
        "      if pert_k < pert:\n",
        "        pert = pert_k\n",
        "        w = w_k\n",
        "    \n",
        "    # compute r_i and r_tot\n",
        "    # Added 1e-4 for numerical stability\n",
        "    r_i = (pert+1e-4) * w / np.linalg.norm(w)\n",
        "    r_tot = np.float32(r_tot + r_i)\n",
        "\n",
        "    if device == torch.device(\"cuda\"):\n",
        "      pert_image = image + (1+overshoot)*torch.from_numpy(r_tot).cuda()\n",
        "    else:\n",
        "      pert_image = image + (1+overshoot)*torch.from_numpy(r_tot)\n",
        "\n",
        "    x = pert_image.clone().detach().requires_grad_(True)\n",
        "    fs = model(x)\n",
        "    k_i = np.argmax(fs.data.cpu().numpy().flatten())\n",
        "    \n",
        "    loop_i += 1\n",
        "\n",
        "  r_tot = (1+overshoot)*r_tot\n",
        "\n",
        "  return pert_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHSVmm2dc0NZ",
        "colab_type": "code",
        "outputId": "35171328-4645-4043-80f9-9a340af0f525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#params = {'epsilon': 0.4}\n",
        "params = {'num_classes': 10, 'overshoot': 0.02, 'max_iter': 50}\n",
        "adv_examples = attack_model(iv3, device, adv_loader, 'deepfool', params, iters=100)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10000 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/10000 [00:00<1:35:14,  1.75it/s]\u001b[A\n",
            "  0%|          | 2/10000 [00:01<1:51:30,  1.49it/s]\u001b[A\n",
            "  0%|          | 3/10000 [00:01<1:42:41,  1.62it/s]\u001b[A\n",
            "  0%|          | 4/10000 [00:02<1:36:30,  1.73it/s]\u001b[A\n",
            "  0%|          | 5/10000 [00:02<1:22:26,  2.02it/s]\u001b[A\n",
            "  0%|          | 6/10000 [00:03<1:23:31,  1.99it/s]\u001b[A\n",
            "  0%|          | 7/10000 [00:03<1:23:13,  2.00it/s]\u001b[A\n",
            "  0%|          | 8/10000 [00:04<1:23:54,  1.98it/s]\u001b[A\n",
            "  0%|          | 9/10000 [00:04<1:23:04,  2.00it/s]\u001b[A\n",
            "  0%|          | 10/10000 [00:05<1:44:18,  1.60it/s]\u001b[A\n",
            "  0%|          | 11/10000 [00:05<1:27:22,  1.91it/s]\u001b[A\n",
            "  0%|          | 12/10000 [00:06<1:25:34,  1.95it/s]\u001b[A\n",
            "  0%|          | 13/10000 [00:07<1:34:47,  1.76it/s]\u001b[A\n",
            "  0%|          | 14/10000 [00:07<1:31:08,  1.83it/s]\u001b[A\n",
            "  0%|          | 15/10000 [00:08<1:39:02,  1.68it/s]\u001b[A\n",
            "  0%|          | 16/10000 [00:09<1:54:18,  1.46it/s]\u001b[A\n",
            "  0%|          | 17/10000 [00:09<1:34:26,  1.76it/s]\u001b[A\n",
            "  0%|          | 18/10000 [00:10<1:40:44,  1.65it/s]\u001b[A\n",
            "  0%|          | 19/10000 [00:10<1:24:54,  1.96it/s]\u001b[A\n",
            "  0%|          | 20/10000 [00:10<1:14:06,  2.24it/s]\u001b[A\n",
            "  0%|          | 21/10000 [00:11<1:37:12,  1.71it/s]\u001b[A\n",
            "  0%|          | 22/10000 [00:12<1:43:06,  1.61it/s]\u001b[A\n",
            "  0%|          | 23/10000 [00:12<1:26:58,  1.91it/s]\u001b[A\n",
            "  0%|          | 24/10000 [00:13<1:15:21,  2.21it/s]\u001b[A\n",
            "  0%|          | 25/10000 [00:13<1:07:22,  2.47it/s]\u001b[A\n",
            "  0%|          | 26/10000 [00:14<1:32:13,  1.80it/s]\u001b[A\n",
            "  0%|          | 27/10000 [00:14<1:39:06,  1.68it/s]\u001b[A\n",
            "  0%|          | 28/10000 [00:15<1:23:44,  1.98it/s]\u001b[A\n",
            "  0%|          | 29/10000 [00:15<1:23:03,  2.00it/s]\u001b[A\n",
            "  0%|          | 30/10000 [00:16<1:22:13,  2.02it/s]\u001b[A\n",
            "  0%|          | 31/10000 [00:16<1:32:09,  1.80it/s]\u001b[A\n",
            "  0%|          | 32/10000 [00:17<1:18:45,  2.11it/s]\u001b[A\n",
            "  0%|          | 33/10000 [00:18<1:39:50,  1.66it/s]\u001b[A\n",
            "  0%|          | 34/10000 [00:18<1:24:30,  1.97it/s]\u001b[A\n",
            "  0%|          | 35/10000 [00:18<1:14:25,  2.23it/s]\u001b[A\n",
            "  0%|          | 36/10000 [00:18<1:06:37,  2.49it/s]\u001b[A\n",
            "  0%|          | 37/10000 [00:19<1:11:32,  2.32it/s]\u001b[A\n",
            "  0%|          | 39/10000 [00:19<57:59,  2.86it/s]  \u001b[A\n",
            "  0%|          | 40/10000 [00:20<1:05:16,  2.54it/s]\u001b[A\n",
            "  0%|          | 41/10000 [00:20<59:42,  2.78it/s]  \u001b[A\n",
            "  0%|          | 43/10000 [00:21<54:30,  3.04it/s]\u001b[A\n",
            "  0%|          | 44/10000 [00:21<52:56,  3.13it/s]\u001b[A\n",
            "  0%|          | 45/10000 [00:21<51:10,  3.24it/s]\u001b[A\n",
            "  0%|          | 46/10000 [00:22<1:01:31,  2.70it/s]\u001b[A\n",
            "  0%|          | 47/10000 [00:22<57:36,  2.88it/s]  \u001b[A\n",
            "  0%|          | 48/10000 [00:22<1:05:06,  2.55it/s]\u001b[A\n",
            "  0%|          | 49/10000 [00:23<1:20:12,  2.07it/s]\u001b[A\n",
            "  0%|          | 50/10000 [00:23<1:10:53,  2.34it/s]\u001b[A\n",
            "  1%|          | 51/10000 [00:24<1:03:36,  2.61it/s]\u001b[A\n",
            "  1%|          | 52/10000 [00:24<1:09:14,  2.39it/s]\u001b[A\n",
            "  1%|          | 53/10000 [00:25<1:02:42,  2.64it/s]\u001b[A\n",
            "  1%|          | 54/10000 [00:25<1:08:29,  2.42it/s]\u001b[A\n",
            "  1%|          | 55/10000 [00:26<1:22:21,  2.01it/s]\u001b[A\n",
            "  1%|          | 56/10000 [00:26<1:12:17,  2.29it/s]\u001b[A\n",
            "  1%|          | 57/10000 [00:26<1:15:13,  2.20it/s]\u001b[A\n",
            "  1%|          | 58/10000 [00:27<1:16:49,  2.16it/s]\u001b[A\n",
            "  1%|          | 59/10000 [00:27<1:08:01,  2.44it/s]\u001b[A\n",
            "  1%|          | 60/10000 [00:28<1:22:58,  2.00it/s]\u001b[A\n",
            "  1%|          | 61/10000 [00:29<1:33:04,  1.78it/s]\u001b[A\n",
            "  1%|          | 62/10000 [00:29<1:30:29,  1.83it/s]\u001b[A\n",
            "  1%|          | 63/10000 [00:29<1:18:02,  2.12it/s]\u001b[A\n",
            "  1%|          | 64/10000 [00:31<1:49:23,  1.51it/s]\u001b[A\n",
            "  1%|          | 65/10000 [00:31<1:51:30,  1.48it/s]\u001b[A\n",
            "  1%|          | 66/10000 [00:32<1:42:02,  1.62it/s]\u001b[A\n",
            "  1%|          | 67/10000 [00:32<1:25:51,  1.93it/s]\u001b[A\n",
            "  1%|          | 68/10000 [00:32<1:14:45,  2.21it/s]\u001b[A\n",
            "  1%|          | 69/10000 [00:33<1:37:49,  1.69it/s]\u001b[A\n",
            "  1%|          | 70/10000 [00:34<1:24:05,  1.97it/s]\u001b[A\n",
            "  1%|          | 71/10000 [00:34<1:13:06,  2.26it/s]\u001b[A\n",
            "  1%|          | 72/10000 [00:34<1:05:20,  2.53it/s]\u001b[A\n",
            "  1%|          | 73/10000 [00:35<1:21:29,  2.03it/s]\u001b[A\n",
            "  1%|          | 74/10000 [00:36<1:32:03,  1.80it/s]\u001b[A\n",
            "  1%|          | 75/10000 [00:36<1:38:57,  1.67it/s]\u001b[A\n",
            "  1%|          | 76/10000 [00:37<2:04:45,  1.33it/s]\u001b[A\n",
            "  1%|          | 77/10000 [00:38<1:41:56,  1.62it/s]\u001b[A\n",
            "  1%|          | 78/10000 [00:38<1:35:16,  1.74it/s]\u001b[A\n",
            "  1%|          | 79/10000 [00:39<1:41:42,  1.63it/s]\u001b[A\n",
            "  1%|          | 80/10000 [00:39<1:25:45,  1.93it/s]\u001b[A\n",
            "  1%|          | 81/10000 [00:40<1:56:13,  1.42it/s]\u001b[A\n",
            "  1%|          | 82/10000 [00:41<1:45:46,  1.56it/s]\u001b[A\n",
            "  1%|          | 83/10000 [00:41<1:37:48,  1.69it/s]\u001b[A\n",
            "  1%|          | 84/10000 [00:42<1:33:48,  1.76it/s]\u001b[A\n",
            "  1%|          | 85/10000 [00:43<2:12:23,  1.25it/s]\u001b[A\n",
            "  1%|          | 86/10000 [00:43<1:47:18,  1.54it/s]\u001b[A\n",
            "  1%|          | 87/10000 [00:44<1:29:36,  1.84it/s]\u001b[A\n",
            "  1%|          | 88/10000 [00:44<1:16:51,  2.15it/s]\u001b[A\n",
            "  1%|          | 89/10000 [00:45<1:18:42,  2.10it/s]\u001b[A\n",
            "  1%|          | 90/10000 [00:45<1:19:33,  2.08it/s]\u001b[A\n",
            "  1%|          | 91/10000 [00:46<1:40:42,  1.64it/s]\u001b[A\n",
            "  1%|          | 92/10000 [00:46<1:24:32,  1.95it/s]\u001b[A\n",
            "  1%|          | 93/10000 [00:47<1:24:17,  1.96it/s]\u001b[A\n",
            "  1%|          | 94/10000 [00:47<1:13:16,  2.25it/s]\u001b[A\n",
            "  1%|          | 95/10000 [00:48<1:47:48,  1.53it/s]\u001b[A\n",
            "  1%|          | 96/10000 [00:48<1:29:47,  1.84it/s]\u001b[A\n",
            "  1%|          | 97/10000 [00:49<1:27:30,  1.89it/s]\u001b[A\n",
            "  1%|          | 98/10000 [00:50<1:35:50,  1.72it/s]\u001b[A\n",
            "  1%|          | 99/10000 [00:50<1:41:02,  1.63it/s]\u001b[A\n",
            "  1%|          | 100/10000 [00:51<1:25:27,  1.93it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== RESULTS ========\n",
            "Test Accuracy = 0 / 100 = 0.0\n",
            "Average confidence = 0.6134357848763465\n",
            "Average time = 0.4524930453300476\n",
            "Average magnitude of perturbations = 2.1094055397994818\n",
            "Model robustness = 0.03373318478057627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I0qERD8yPZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attack_model(model, device, test_loader, method, params, iters=10000):\n",
        "\n",
        "  # Initialize the network and set the model in evaluation mode.\n",
        "  model = model.to(device).eval()\n",
        "\n",
        "  # Stat counters\n",
        "  correct = 0\n",
        "  confidence = 0\n",
        "  total_time = 0\n",
        "  ex_robustness = 0\n",
        "  model_robustness = 0\n",
        "  adv_examples = []\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  # Loop (iters) examples in test set\n",
        "  for data, target in pbar(test_loader):\n",
        "    if i >= iters:\n",
        "      break\n",
        "    i += 1\n",
        "\n",
        "    # Send the data and label to the device\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Set requires_grad attribute of tensor. Important for Attack\n",
        "    if method in ['fgsm', 'deepfool']:\n",
        "        data.requires_grad = True\n",
        "\n",
        "    # Forward pass the data through the model\n",
        "    output = model(data)\n",
        "    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "    # If the initial prediction is wrong, dont botter attacking\n",
        "    if init_pred.item() != target.item():\n",
        "      continue\n",
        "\n",
        "    if method == 'fgsm':\n",
        "        # Call FGSM attack\n",
        "        time_ini = time.time()\n",
        "        perturbed_data = fgsm(model, data, params[\"epsilon\"], output, target)\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "      \n",
        "    elif method == 'deepfool':\n",
        "        # Call DeepFool attack\n",
        "        time_ini = time.time()\n",
        "        perturbed_data = deepfool(model, device, data, target.item(), output, params[\"num_classes\"], params[\"overshoot\"], params[\"max_iter\"])\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "\n",
        "    # Update model robustness\n",
        "    p_norm = 2\n",
        "    im_np = data.squeeze().detach().cpu().numpy()\n",
        "    adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "    delta = np.linalg.norm((adv_ex - im_np).flatten(), ord=p_norm)\n",
        "    #delta = math.sqrt(32*32*3*params[\"epsilon\"]**2)  # fgsm has a fixed delta(f,x) robustness\n",
        "    ex_robustness += delta\n",
        "    model_robustness += delta / np.linalg.norm(im_np.flatten(), ord=p_norm)\n",
        "\n",
        "    # Re-classify the perturbed image\n",
        "    output = model(perturbed_data)\n",
        "\n",
        "    # Check for success\n",
        "    final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "    confidence += F.softmax(output, dim=1).max(1, keepdim=True)[0].item()  # adv. confidence\n",
        "    if final_pred.item() == target.item():\n",
        "      correct += 1\n",
        "    else:\n",
        "      # Save some adv examples for visualization later\n",
        "      if len(adv_examples) < 5:\n",
        "        adv_examples.append( (init_pred.item(), final_pred.item(), im_np, adv_ex) )\n",
        "\n",
        "  # Calculate stats\n",
        "  final_acc = correct / float(iters)  # len(test_loader)\n",
        "  avg_confidence = confidence / float(iters)\n",
        "  avg_time = total_time / float(iters)\n",
        "  avg_ex_robustness = ex_robustness / float(iters)\n",
        "  model_robustness = model_robustness / float(iters)\n",
        "  print(\"\\n======== RESULTS ========\")\n",
        "  print(\"Test Accuracy = {} / {} = {}\\nAverage confidence = {}\\nAverage time = {}\\nAverage magnitude of perturbations = {}\\nModel robustness = {}\"\n",
        "    .format(correct, iters, final_acc, avg_confidence, avg_time, avg_ex_robustness, model_robustness))\n",
        "\n",
        "  # Return adversarial examples\n",
        "  return adv_examples"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}