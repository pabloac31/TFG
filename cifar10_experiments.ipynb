{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_experiments.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNglvKurSTtTdfPdF2boGU0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ebff74634b742858bd4c17b657c2d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f4fa36d7112449c94ad17e39aa22023",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a0bfd24187f4aa7b945967c0d75f877",
              "IPY_MODEL_12617787153f40a39b8a34b54c9fc9c5"
            ]
          }
        },
        "2f4fa36d7112449c94ad17e39aa22023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a0bfd24187f4aa7b945967c0d75f877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_07b120ee60e74b1ab5a55c9fab7895c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14fde11a9c464917b16714f8c2b2d318"
          }
        },
        "12617787153f40a39b8a34b54c9fc9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7cbd6e8970dc4a539d10cffdaf62e6b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:30&lt;00:00, 14471378.92it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cff70b85cd3942cd8684ca0a4f2fc95a"
          }
        },
        "07b120ee60e74b1ab5a55c9fab7895c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14fde11a9c464917b16714f8c2b2d318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7cbd6e8970dc4a539d10cffdaf62e6b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cff70b85cd3942cd8684ca0a4f2fc95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pabloac31/TFG/blob/master/cifar10_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZIrtm8vDL9s",
        "colab_type": "text"
      },
      "source": [
        "**Clone the repository**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6ctRAXTcHH2",
        "colab_type": "code",
        "outputId": "136ee212-fa7e-4f76-9b87-c6fdbd1dd456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "! git clone https://github.com/pabloac31/TFG.git\n",
        "%cd TFG"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TFG'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 202 (delta 9), reused 7 (delta 3), pack-reused 183\u001b[K\n",
            "Receiving objects: 100% (202/202), 217.20 MiB | 11.54 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n",
            "Checking out files: 100% (30/30), done.\n",
            "/content/TFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmR1_uT1ELeN",
        "colab_type": "text"
      },
      "source": [
        "**Using Tensorflow v1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1YD-wgycX9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wThIjzaBEWab",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Qs_zdCcZS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cifar10_models import *\n",
        "from utils import *\n",
        "from adversarial_attacks import *\n",
        "import statistics "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFqYGnBSFMxL",
        "colab_type": "text"
      },
      "source": [
        "**Use CUDA if available for increase speed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ugar45Fcrmo",
        "colab_type": "code",
        "outputId": "aa678224-1f5e-41ed-9082-25d2c835bd31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "use_cuda=True\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eLXv5lbGHwx",
        "colab_type": "text"
      },
      "source": [
        "**Create dataloaders**\n",
        "\n",
        "Load CIFAR10 test images as tensors of size NxCxHxW normalized with CIFAR10 mean and std."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8pZ6UNBctah",
        "colab_type": "code",
        "outputId": "b117ec3a-4826-44db-a73d-dad6fe2078bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "0ebff74634b742858bd4c17b657c2d77",
            "2f4fa36d7112449c94ad17e39aa22023",
            "7a0bfd24187f4aa7b945967c0d75f877",
            "12617787153f40a39b8a34b54c9fc9c5",
            "07b120ee60e74b1ab5a55c9fab7895c2",
            "14fde11a9c464917b16714f8c2b2d318",
            "7cbd6e8970dc4a539d10cffdaf62e6b0",
            "cff70b85cd3942cd8684ca0a4f2fc95a"
          ]
        }
      },
      "source": [
        "test_loader = testloader_cifar10('./data', batch_size=256, shuffle=False)  # Dataloader for testing the model \n",
        "adv_loader = testloader_cifar10('./data', batch_size=1)                    # Dataloader for adversarial attacks\n",
        "univ_loader = testloader_cifar10('./data', batch_size=1, shuffle=False)    # Dataloader for universal attack"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ebff74634b742858bd4c17b657c2d77",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7h0dj4BE-U7",
        "colab_type": "text"
      },
      "source": [
        "**Load models pretrained on CIFAR10**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq7UhHCkcpW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet = resnet50(pretrained=True)\n",
        "densenet = densenet169(pretrained=True)\n",
        "mobnet = mobilenet_v2(pretrained=True)\n",
        "iv3 = inception_v3(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HMLdKZWGvKt",
        "colab_type": "text"
      },
      "source": [
        "**Test models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JwdTaCecvpK",
        "colab_type": "code",
        "outputId": "d40c8f54-54dd-4291-c0bd-1eae043d011b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "acc = test_model(mobnet, device, test_loader)\n",
        "print('\\nAccuracy on CIFAR10 test set: ', acc)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:03<00:00, 10.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy on CIFAR10 test set:  0.9299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5-jN371fV32",
        "colab_type": "text"
      },
      "source": [
        "**Set method parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVW-1y_PfhF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_fgsm = {'epsilon': 0.01, 'clip': True}\n",
        "params_deepfool = {'num_classes': 10, 'overshoot': 0.01, 'max_iter': 50, 'p': 2, 'clip': True}\n",
        "params_sparsefool = {'delta': 255, 'lambda_': 3.0, 'max_iter': 50, 'epsilon': 0.02}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4ipPW1fexSV",
        "colab_type": "text"
      },
      "source": [
        "**Test methods**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHUn30pJcyPK",
        "colab_type": "code",
        "outputId": "1cab4314-73d5-4612-b6ec-548ccc50c2c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "image, label = next(iter(adv_loader))\n",
        "test_method(mobnet, device, image, label, method='sparsefool', params=params_sparsefool)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Succesful attack!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Number of iterations needed:  1\n",
            "Number of perturbed pixels:  3072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiUyFraoe-Xh",
        "colab_type": "text"
      },
      "source": [
        "**Perform a complete attack and show results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHSVmm2dc0NZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#params = {'target_label': None, 'iters': 10, 'pop_size': 100, 'verbose': True}\n",
        "\n",
        "adv_examples = attack_model(resnet, device, adv_loader, 'sparsefool', params_sparsefool, iters=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-ofMESf1V2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" SPARSEFOOL \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "def linear_solver(x_0, normal, boundary_point, lb, ub):\n",
        "  \n",
        "  # Initialize variables\n",
        "  input_shape = x_0.size()\n",
        "  coord_vec = copy.deepcopy(normal)\n",
        "\n",
        "  # Obtain plane normal vector and boundary point\n",
        "  plane_normal = copy.deepcopy(coord_vec).view(-1)\n",
        "  plane_point = copy.deepcopy(boundary_point).view(-1)\n",
        "\n",
        "  x_i = copy.deepcopy(x_0)   # x(0) <- x_0\n",
        "\n",
        "  # \"Linearized\" classifier\n",
        "  f_k = torch.dot(plane_normal, x_0.view(-1) - plane_point)\n",
        "  sign_true = f_k.sign().item()\n",
        "  print(sign_true)\n",
        "\n",
        "  beta = 0.001 * sign_true\n",
        "  current_sign = sign_true\n",
        "\n",
        "  while current_sign == sign_true and coord_vec.nonzero().size()[0] > 0:  # while w^T(x_i - x_B) != 0\n",
        "\n",
        "    # Update f_k\n",
        "    f_k = torch.dot(plane_normal, x_i.view(-1) - plane_point) + beta\n",
        "\n",
        "    # Maximum |w_j|\n",
        "    pert = f_k.abs() / coord_vec.abs().max()\n",
        "\n",
        "    mask = torch.zeros_like(coord_vec)\n",
        "    mask[np.unravel_index(torch.argmax(coord_vec.abs().cpu()), input_shape)] = 1.\n",
        "\n",
        "    # Update r_i\n",
        "    r_i = torch.clamp(pert, min=1e-4) * mask * coord_vec.sign()\n",
        "\n",
        "    # Update perturbation with the desired constraints\n",
        "    x_i = x_i + r_i\n",
        "    x_i = clip_image_values(x_i, lb, ub)\n",
        "\n",
        "    # Update predictions\n",
        "    f_k = torch.dot(plane_normal, x_i.view(-1) - plane_point)\n",
        "    current_sign = f_k.sign().item()\n",
        "\n",
        "    coord_vec[r_i != 0] = 0\n",
        "\n",
        "  return x_i.detach()  # for deepcopy\n",
        "\n",
        "\n",
        "def sparsefool(model, device, x_0, label, lb, ub, lambda_=3., max_iter=20, epsilon=0.02):\n",
        "\n",
        "  # Initialize variables\n",
        "  x_i = copy.deepcopy(x_0)\n",
        "  fool_im = copy.deepcopy(x_i)\n",
        "  fool_label = label\n",
        "  loops = 0\n",
        "\n",
        "  while fool_label == label and loops < max_iter:\n",
        "\n",
        "    # Compute l2 adversarial perturbation (using DeepFool)\n",
        "    normal, x_adv,_,_ = deepfool(model, device, x_i, lambda_fac=lambda_)\n",
        "\n",
        "    # Update x_i using the linear solver\n",
        "    x_i = linear_solver(x_i, normal, x_adv, lb, ub)\n",
        "\n",
        "    # Adding epsilon to compute fool_im\n",
        "    fool_im = x_0 + (1 + epsilon) * (x_i - x_0)\n",
        "    # Clip values using lb, ub\n",
        "    fool_im = clip_image_values(fool_im, lb, ub)\n",
        "    # Obtain current prediction\n",
        "    x = fool_im.clone().detach().requires_grad_(True)\n",
        "    fool_label = torch.argmax(model(x).data).item()\n",
        "\n",
        "    loops += 1\n",
        "\n",
        "  r = fool_im - x_0\n",
        "  return fool_im, r, loops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xseEdeDnHlGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v = universal_perturbation(univ_loader, iv3, device, delta=0.1)\n",
        "\n",
        "plt.imshow(denormalize_cifar10(v[0].cpu().detach().numpy()).transpose((1,2,0)))\n",
        "plt.title('Universal perturbation')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTnsNwRMmxWt",
        "colab_type": "code",
        "outputId": "de85220c-075a-412b-9379-2359bd7132c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "image = Image.open('./data/img1.png')\n",
        "x = TF.to_tensor(image)\n",
        "x = normalize_cifar10(x)\n",
        "x = x.unsqueeze_(0).to(device)\n",
        "label = torch.tensor([1]).to(device)\n",
        "print('Label:', label.item())\n",
        "x.requires_grad = True\n",
        "y = iv3(x)\n",
        "init_pred = y.max(1, keepdim=True)[1]\n",
        "print(\"Original image prediction: \", init_pred.item())\n",
        "x_r = x.add(v).to(device)\n",
        "pred = iv3(x_r).max(1, keepdim=True)[1]\n",
        "print(\"Perturbed image prediction: \", pred.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 1\n",
            "Original image prediction:  1\n",
            "Perturbed image prediction:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoSdwQ1ne1mA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img, label = next(iter(adv_loader))\n",
        "im = denormalize_cifar10(img.numpy()[0].copy()).transpose((1,2,0))\n",
        "plt.imshow(im)\n",
        "plt.show()\n",
        "label = label.item()\n",
        "success, sol, score = one_pixel_attack(iv3, device, img, label, pop_size=400, iters=20)\n",
        "print(success)\n",
        "print(score)\n",
        "adv = perturb(sol, img)\n",
        "im = denormalize_cifar10(adv.numpy()[0].copy()).transpose((1,2,0))\n",
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CU4A8L3KmqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_method(model, device, img, label, method, params):\n",
        "\n",
        "  img = img.clone()\n",
        "\n",
        "  model = model.to(device).eval()\n",
        "\n",
        "  x = img.to(device)\n",
        "  label = label.to(device)\n",
        "\n",
        "  x.requires_grad = True\n",
        "\n",
        "  y = model(x)\n",
        "  init_pred = y.max(1, keepdim=True)[1]\n",
        "  x_conf = F.softmax(y, dim=1).max(1, keepdim=True)[0].item()  \n",
        "\n",
        "  if init_pred.item() != label.item():\n",
        "    print(\"Wrong classification...\")\n",
        "    return\n",
        "\n",
        "  # Call method\n",
        "  if method == 'fgsm':\n",
        "    adv_x, pert_x = fgsm(model, x, label, y, params[\"epsilon\"], params[\"clip\"])\n",
        "\n",
        "  elif method == 'deepfool':\n",
        "    _, adv_x, pert_x, n_iter = deepfool(model, device, x, params[\"num_classes\"], overshoot=params[\"overshoot\"], max_iter=params[\"max_iter\"], p=params[\"p\"], clip=params[\"clip\"])\n",
        "\n",
        "  elif method == 'sparsefool':\n",
        "    # Generate lower and upper bounds\n",
        "    delta = params[\"delta\"]\n",
        "    lb, ub =  valid_bounds(x, delta, dataset='cifar10')\n",
        "    lb = lb[None, :, :, :].to(device)\n",
        "    ub = ub[None, :, :, :].to(device)\n",
        "    adv_x, pert_x, n_iter = sparsefool(model, device, x, label.item(), lb, ub, params[\"lambda_\"], params[\"max_iter\"], params[\"epsilon\"])\n",
        "\n",
        "  elif method == 'one_pixel_attack':\n",
        "    _, best_sol, score = one_pixel_attack(model, device, data, target.item(), params[\"target_label\"], params[\"iters\"], params[\"pop_size\"], params[\"verbose\"])\n",
        "    adv_x = perturb(best_sol, data)\n",
        "\n",
        "  y_adv = model(adv_x)\n",
        "  adv_pred = y_adv.max(1, keepdim=True)[1]\n",
        "  adv_x_conf = F.softmax(y_adv, dim=1).max(1, keepdim=True)[0].item()  \n",
        "\n",
        "  if adv_pred.item() == label.item():\n",
        "    print(\"Attack failed...\")\n",
        "\n",
        "  else:\n",
        "    print(\"Succesful attack!\")\n",
        "\n",
        "  f = plt.figure()\n",
        "  f.add_subplot(1,3,1)\n",
        "  plt.title('Original image')\n",
        "  plt.axis('off')\n",
        "  f.text(.25, .3, cifar10_classes[label.item()] + ' ({:.2f}%)'.format(x_conf*100), ha='center')\n",
        "  plt.imshow(displayable(img))\n",
        "  f.add_subplot(1,3,2)\n",
        "  plt.title('Perturbation')\n",
        "  plt.axis('off')\n",
        "  plt.imshow(displayable(pert_x.cpu().detach()))\n",
        "  f.add_subplot(1,3,3)\n",
        "  plt.title('Adv. image')\n",
        "  plt.axis('off')\n",
        "  f.text(.8, .3, cifar10_classes[adv_pred.item()] + ' ({:.2f}%)'.format(adv_x_conf*100), ha='center')\n",
        "  plt.imshow(displayable(adv_x.cpu().detach()))\n",
        "  plt.show(block=True)\n",
        "\n",
        "  if method in ['deepfool',  'sparsefool']:\n",
        "    print('Number of iterations needed: ', n_iter)\n",
        "\n",
        "  if method == 'sparsefool':\n",
        "    pert_pixels = pert_x.flatten().nonzero().size(0)\n",
        "    print('Number of perturbed pixels: ', pert_pixels) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zxW6hZmQfyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attack_model(model, device, test_loader, method, params, p=2, iters=10000, dataset='cifar10'):\n",
        "\n",
        "  # Initialize the network and set the model in evaluation mode.\n",
        "  model = model.to(device).eval()\n",
        "\n",
        "  # Initialize stat counters\n",
        "  correct = 0\n",
        "  incorrect = 0\n",
        "  confidence = 0\n",
        "  total_time = 0\n",
        "  ex_robustness = 0\n",
        "  model_robustness = 0\n",
        "  method_iters = 0\n",
        "  n_pert_pixels = []\n",
        "  adv_examples = []\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  # Loop (iters) examples in test set\n",
        "  for data, target in pbar(test_loader):\n",
        "    if i >= iters:\n",
        "      break\n",
        "    i += 1\n",
        "\n",
        "    # Send the data and label to the device\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Set requires_grad attribute of tensor (important for some attacks)\n",
        "    if method in ['fgsm', 'deepfool', 'sparsefool']:\n",
        "        data.requires_grad = True\n",
        "\n",
        "    # Forward pass the data through the model\n",
        "    output = model(data)\n",
        "    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "    # If the initial prediction is wrong, dont botter attacking\n",
        "    if init_pred.item() != target.item():\n",
        "      continue\n",
        "\n",
        "    if method == 'fgsm':\n",
        "        # Call FGSM attack\n",
        "        time_ini = time.time()\n",
        "        perturbed_data, _ = fgsm(model, data, target, output, params[\"epsilon\"], params[\"clip\"], dataset)\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "\n",
        "    elif method == 'deepfool':\n",
        "        # Call DeepFool attack\n",
        "        time_ini = time.time()\n",
        "        _, perturbed_data, _, n_iter = deepfool(model, device, data, params[\"num_classes\"], overshoot=params[\"overshoot\"], max_iter=params[\"max_iter\"], p=params[\"p\"], clip=params[\"clip\"])\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "        method_iters += n_iter\n",
        "\n",
        "    elif method == 'sparsefool':\n",
        "        # Generate lower and upper bounds\n",
        "        delta = params[\"delta\"]\n",
        "        lb, ub =  valid_bounds(data, delta, dataset='cifar10')\n",
        "        lb = lb[None, :, :, :].to(device)\n",
        "        ub = ub[None, :, :, :].to(device)\n",
        "        # Call SparseFool attack\n",
        "        time_ini = time.time()\n",
        "        perturbed_data, perturbation, n_iter = sparsefool(model, device, data, target.item(), lb, ub, params[\"lambda_\"], params[\"max_iter\"], params[\"epsilon\"])\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "        method_iters += n_iter\n",
        "        n_pert_pixels.append(perturbation.flatten().nonzero().size(0))\n",
        "\n",
        "    elif method == 'one_pixel_attack':\n",
        "        # Call one pixel attack\n",
        "        time_ini = time.time()\n",
        "        _, best_sol, score = one_pixel_attack(model, device, data, target.item(), params[\"target_label\"], params[\"iters\"], params[\"pop_size\"], params[\"verbose\"])\n",
        "        perturbed_data = perturb(best_sol, data)\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "\n",
        "\n",
        "    # Update model robustness\n",
        "    # multiply by std to make it independent of the normalization used\n",
        "    difference = de_scale(perturbed_data-data, dataset)\n",
        "    if p == 2:\n",
        "      adv_rob = torch.norm(difference)  # Frobenius norm (p=2)\n",
        "      model_robustness += adv_rob / torch.norm(de_scale(data, dataset))\n",
        "    elif p == np.inf:\n",
        "      adv_rob = torch.norm(difference, float('inf'))  # Inf norm (p=inf)\n",
        "      model_robustness += adv_rob / torch.norm(de_scale(data, dataset), float('inf'))\n",
        "    ex_robustness += adv_rob\n",
        "    \n",
        "    # Re-classify the perturbed image\n",
        "    output = model(perturbed_data)\n",
        "\n",
        "    # Check for success\n",
        "    final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "    \n",
        "    if final_pred.item() == target.item():\n",
        "      correct += 1\n",
        "    \n",
        "    else:\n",
        "      incorrect += 1\n",
        "      # Update average confidence\n",
        "      confidence += F.softmax(output, dim=1).max(1, keepdim=True)[0].item()  \n",
        "      # Save some adv examples for visualization later\n",
        "      if len(adv_examples) < 5:\n",
        "        adv_examples.append( (init_pred.item(), final_pred.item(), data.detach().cpu(), perturbed_data.detach().cpu()) )\n",
        "\n",
        "  # Calculate stats\n",
        "  final_acc = correct / float(iters)  # len(test_loader)\n",
        "  avg_confidence = confidence / float(incorrect)\n",
        "  avg_time = total_time / float(correct+incorrect)\n",
        "  avg_ex_robustness = ex_robustness / float(correct+incorrect)\n",
        "  model_robustness = model_robustness / float(correct+incorrect)\n",
        "  print(\"\\n======== RESULTS ========\")\n",
        "  print(\"Test Accuracy = {} / {} = {:.4f}\\nAverage confidence = {:.4f}\\nAverage time = {:.4f}\\nAverage magnitude of perturbations = {:.4f}\\nModel robustness = {:.4f}\"\n",
        "    .format(correct, iters, final_acc, avg_confidence, avg_time, avg_ex_robustness, model_robustness))\n",
        "\n",
        "  if method in ['deepfool', 'sparsefool']:\n",
        "    print(\"Avg. iters = {:.2f}\".format(method_iters / float(correct+incorrect)))\n",
        "\n",
        "  if method == 'sparsefool':\n",
        "    print(\"Median num. of pixels perturbed = \", statistics.median(n_pert_pixels))\n",
        "\n",
        "  # Return adversarial examples\n",
        "  return adv_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-F8_drp9Hur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" DEEPFOOL \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "def deepfool(model, device, im, num_classes=10, overshoot=0.02, lambda_fac=1.01, max_iter=50, p=2, clip=False, dataset='cifar10'):\n",
        "\n",
        "  image = copy.deepcopy(im)\n",
        "\n",
        "  # Get the input image shape\n",
        "  input_shape = image.size()\n",
        "\n",
        "  # Get the output of the original image\n",
        "  output = model(image)\n",
        " \n",
        "  # Array with the class probabilities of the image\n",
        "  f_image = output.data.cpu().numpy().flatten()\n",
        "  # Classes ordered by probability (descending)\n",
        "  I = f_image.argsort()[::-1]\n",
        "  # We consider only 'num_classes' classes\n",
        "  I = I[0:num_classes]\n",
        "\n",
        "  # Get the predicted label\n",
        "  label = I[0]\n",
        "\n",
        "  # Start from a copy of the original image\n",
        "  pert_image = copy.deepcopy(image)   # tensor of size (1,3,H,W)\n",
        "\n",
        "  # Initialize variables\n",
        "  r_tot = torch.zeros(input_shape).to(device) # adversarial perturbation\n",
        "  k_i = label  # current label\n",
        "  loop_i = 0\n",
        "\n",
        "  while k_i == label and loop_i < max_iter:\n",
        "\n",
        "    # Get the output for the current image\n",
        "    x = pert_image.clone().detach().requires_grad_(True)\n",
        "    fs = model(x)\n",
        "\n",
        "    pert = torch.Tensor([np.inf])[0].to(device)\n",
        "    w = torch.zeros(input_shape).to(device)\n",
        "\n",
        "    # Calculate grad(f_label(x_i))\n",
        "    fs[0, I[0]].backward(retain_graph=True)\n",
        "    grad_orig = copy.deepcopy(x.grad.data)\n",
        "\n",
        "    for k in range(1, num_classes):  # for k != label\n",
        "      # Reset gradients\n",
        "      zero_gradients(x)\n",
        "\n",
        "      # Calculate grad(f_k(x_i))\n",
        "      fs[0, I[k]].backward(retain_graph=True)\n",
        "      cur_grad = copy.deepcopy(x.grad.data)\n",
        "\n",
        "      # Set new w_k and new f_k\n",
        "      w_k = cur_grad - grad_orig\n",
        "      f_k = (fs[0, I[k]] - fs[0, I[0]]).data\n",
        "\n",
        "      # Calculate hyperplane-k distance\n",
        "      if p == 2:\n",
        "        pert_k = torch.abs(f_k) / w_k.norm()  # Frobenious norm (2-norm)\n",
        "      elif p == np.inf:\n",
        "        pert_k = torch.abs(f_k) / w_k.norm(1) # 1-norm\n",
        "\n",
        "      # determine which w_k to use\n",
        "      if pert_k < pert:\n",
        "        pert = pert_k + 0.\n",
        "        w = w_k + 0.\n",
        "\n",
        "    # compute r_i and r_tot\n",
        "    if p == 2:\n",
        "      r_i = torch.clamp(pert, min=1e-4) * w / w.norm()  # Added 1e-4 for numerical stability\n",
        "    elif p == np.inf:\n",
        "      r_i = torch.clamp(pert, min=1e-4) * torch.sign(w)\n",
        "\n",
        "    r_tot = r_tot + r_i\n",
        "\n",
        "    # Update perturbed image\n",
        "    pert_image = pert_image + r_i  # x_(i+1) <- x_i + r_i\n",
        "\n",
        "    # Adding overshoot\n",
        "    check_fool = image + (1 + overshoot) * r_tot\n",
        "\n",
        "    x = check_fool.clone().detach().requires_grad_(True)\n",
        "    # output for x_(i+1)\n",
        "    fs = model(x)\n",
        "    # label assigned to x_(i+1)\n",
        "    k_i = torch.argmax(fs.data).item()\n",
        "\n",
        "    loop_i += 1\n",
        "\n",
        "  # Compute final perturbed image output\n",
        "  x = pert_image.clone().detach().requires_grad_(True)\n",
        "  fs = model(x)\n",
        "  # Compute final gradient\n",
        "  (fs[0, k_i] - fs[0, label]).backward(retain_graph=True)\n",
        "  grad = copy.deepcopy(x.grad.data)\n",
        "  grad = grad / grad.norm()\n",
        "\n",
        "  # Include lambda_fac in the adversarial perturbation\n",
        "  r_tot = lambda_fac * r_tot  # for SparseFool\n",
        "\n",
        "  # Adding clipping to maintain [0,1] range\n",
        "  if clip:\n",
        "    pert_image = clamp(image + r_tot, 0, 1, dataset)\n",
        "\n",
        "  else:\n",
        "    pert_image = (image + r_tot).clone().detach()\n",
        "\n",
        "  return grad, pert_image, r_tot, loop_i"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}