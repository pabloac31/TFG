{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_experiments.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPpPkaI8Bh/ia/h2nz7gwXw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pabloac31/TFG/blob/master/cifar10_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZIrtm8vDL9s",
        "colab_type": "text"
      },
      "source": [
        "**Clone the repository**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6ctRAXTcHH2",
        "colab_type": "code",
        "outputId": "614c2544-6d5a-4b35-fa03-9f321db103ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "! git clone https://github.com/pabloac31/TFG.git\n",
        "%cd TFG"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TFG'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 234 (delta 30), reused 15 (delta 7), pack-reused 183\u001b[K\n",
            "Receiving objects: 100% (234/234), 217.28 MiB | 13.38 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n",
            "Checking out files: 100% (30/30), done.\n",
            "/content/TFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmR1_uT1ELeN",
        "colab_type": "text"
      },
      "source": [
        "**Using Tensorflow v1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1YD-wgycX9P",
        "colab_type": "code",
        "outputId": "24160751-4de8-4917-8cf4-0df01db5c463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wThIjzaBEWab",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Qs_zdCcZS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cifar10_models import *\n",
        "from utils import *\n",
        "from adversarial_attacks import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFqYGnBSFMxL",
        "colab_type": "text"
      },
      "source": [
        "**Use CUDA if available for increase speed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ugar45Fcrmo",
        "colab_type": "code",
        "outputId": "9b38018a-2865-43b1-fbb4-94d31b006291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "use_cuda=True\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eLXv5lbGHwx",
        "colab_type": "text"
      },
      "source": [
        "**Create dataloaders**\n",
        "\n",
        "Load CIFAR10 test images as tensors of size NxCxHxW normalized with CIFAR10 mean and std."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8pZ6UNBctah",
        "colab_type": "code",
        "outputId": "a7c45aa5-e757-4ad7-ddbf-dff4d7fd4444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "test_loader = testloader_cifar10('./data', batch_size=256, shuffle=False)  # Dataloader for testing the model \n",
        "adv_loader = testloader_cifar10('./data', batch_size=1)                    # Dataloader for adversarial attacks\n",
        "univ_loader = testloader_cifar10('./data', batch_size=1000, shuffle=False) # Dataloader for universal attack\n",
        "full_loader = testloader_cifar10('./data', batch_size=10000, shuffle=False)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7h0dj4BE-U7",
        "colab_type": "text"
      },
      "source": [
        "**Load models pretrained on CIFAR10**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq7UhHCkcpW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet = resnet50(pretrained=True)\n",
        "densenet = densenet169(pretrained=True)\n",
        "mobnet = mobilenet_v2(pretrained=True)\n",
        "iv3 = inception_v3(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HMLdKZWGvKt",
        "colab_type": "text"
      },
      "source": [
        "**Test models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JwdTaCecvpK",
        "colab_type": "code",
        "outputId": "491908c3-0e14-4fbc-ac72-290b587357f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "acc = test_model(resnet, device, test_loader)\n",
        "print('\\nAccuracy on CIFAR10 test set: ', acc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:09<00:00,  4.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy on CIFAR10 test set:  0.9212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5-jN371fV32",
        "colab_type": "text"
      },
      "source": [
        "**Set method parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVW-1y_PfhF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_fgsm = {'epsilon': 0.01, 'clip': True}\n",
        "params_deepfool = {'num_classes': 10, 'overshoot': 0.01, 'max_iter': 50, 'p': 2, 'clip': True}\n",
        "params_sparsefool = {'delta': 255, 'lambda_': 3.0, 'max_iter': 50, 'epsilon': 0.02}\n",
        "params_opa = {'dim': 3, 'target_label': None, 'iters': 100, 'pop_size': 400, 'verbose': True}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4ipPW1fexSV",
        "colab_type": "text"
      },
      "source": [
        "**Test methods**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHUn30pJcyPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image, label = next(iter(adv_loader))\n",
        "\n",
        "scores = test_method(mobnet, device, image, label, method='one_pixel_attack', params=params_opa)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiUyFraoe-Xh",
        "colab_type": "text"
      },
      "source": [
        "**Perform a complete attack and show results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHSVmm2dc0NZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adv_examples = attack_model(mobnet, device, univ_loader, 'one_pixel_attack', params_opa, iters=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kesKwfPN5u9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3accb8a2-82f9-466b-eb71-2166a0e3ae0c"
      },
      "source": [
        "dataset, labels = next(iter(univ_loader))\n",
        "print(dataset.size())\n",
        "print(labels.size())\n",
        "\n",
        "testset, labels_test = next(iter(full_loader))\n",
        "print(testset.size())\n",
        "print(labels_test.size())"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 3, 32, 32])\n",
            "torch.Size([1000])\n",
            "torch.Size([10000, 3, 32, 32])\n",
            "torch.Size([10000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xseEdeDnHlGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "b1d5d161-c355-4543-e9a0-f61f021c5924"
      },
      "source": [
        "v = universal_perturbation(dataset, labels, mobnet, device, delta=0.2, xi=5, max_iter_uni=10, p=2, v_ini=None)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting pass number  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-8c3d788f0fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniversal_perturbation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmobnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter_uni\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_ini\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-80-a864f9b67cb3>\u001b[0m in \u001b[0;36muniversal_perturbation\u001b[0;34m(dataset, labels, model, device, delta, xi, max_iter_uni, p, num_classes, overshoot, max_iter_df, v_ini)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mest_labels_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mest_labels_pert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_perturbed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TFG/cifar10_models/mobilenetv2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1921\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1922\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m     )\n\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 11.17 GiB total capacity; 10.42 GiB already allocated; 31.81 MiB free; 10.83 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kQapiu1H1Et",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d0d789b9-ad51-4b89-cd0d-d3477d7cda24"
      },
      "source": [
        "univ_fool_rate(resnet, device, testset, v, batch_size=250)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:13<00:00,  3.00it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2367"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwE1abQKKEHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "d5c2f176-eef1-4f01-bedd-9cde17f359e1"
      },
      "source": [
        "plt.imshow(displayable(v.cpu()))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f404edb1cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07i5AhXUl9K3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def universal_perturbation(dataset, labels, model, device, delta=0.2, xi=10, max_iter_uni=10, p=2, num_classes=10, overshoot=0.02, max_iter_df=10, v_ini=None):\n",
        "\n",
        "  # Initialize the network and set the model in evaluation mode.\n",
        "  model = model.to(device).eval()\n",
        "  dataset = dataset.to(device)\n",
        "  labels = labels.to(device)\n",
        "\n",
        "  v = v_ini if v_ini is not None else torch.zeros((1, dataset.size()[1], dataset.size()[2], dataset.size()[3])).to(device)\n",
        "  fooling_rate = 0.0\n",
        "  num_images = dataset.size()[0]\n",
        "  \n",
        "  itr = 0\n",
        "  while fooling_rate < 1-delta and itr < max_iter_uni:\n",
        "\n",
        "    v_prev = v.clone()\n",
        "    foolrate_prev = fooling_rate\n",
        "\n",
        "    # Shuffle the dataset\n",
        "    order = np.arange(num_images)\n",
        "    np.random.shuffle(order)\n",
        "    dataset[np.arange(num_images)] = dataset[order]\n",
        "    labels[np.arange(num_images)] = labels[order]\n",
        "    \n",
        "    print('Starting pass number ', itr)\n",
        "\n",
        "    # Go through the data set and compute the perturbation increments sequentially\n",
        "    for k in range(num_images):\n",
        "      cur_img = dataset[k:(k+1), :, :, :]\n",
        "      label = labels[k]\n",
        "\n",
        "      pred_label = model(cur_img).max(1, keepdim=True)[1].item()\n",
        "\n",
        "      if pred_label == label.item() and model(cur_img + v).max(1, keepdim=True)[1].item() == pred_label:\n",
        "\n",
        "        # Compute adversarial perturbation\n",
        "        _, _, dr, loop_i = deepfool(model, device, cur_img + v, num_classes=num_classes, overshoot=overshoot, lambda_fac=1+overshoot, max_iter=max_iter_df, p=p)\n",
        "\n",
        "        # Make sure it converged...\n",
        "        if loop_i < max_iter_df-1:\n",
        "          v = v + dr\n",
        "\n",
        "          # Project on the lp ball centered at 0 and of radius xi\n",
        "          if p == 2:\n",
        "            v = v * min(1, xi / v.norm())\n",
        "          elif p == np.inf:\n",
        "            v = torch.sign(v) * torch.min(torch.abs(v), torch.full_like(v, xi))\n",
        "\n",
        "    itr += 1\n",
        "    \n",
        "    # Perturb the dataset with cumputed perturbation\n",
        "    dataset_perturbed = dataset + v\n",
        "\n",
        "    batch_size = 250\n",
        "    num_batches = np.int(np.ceil(np.float(num_images) / np.float(batch_size)))\n",
        "    fooling_rate = 0.0\n",
        "\n",
        "    # Compute the estimated labels in batches\n",
        "    for ii in pbar(range(num_batches)):\n",
        "        m = (ii * batch_size)\n",
        "        M = min((ii+1)*batch_size, num_images)\n",
        "\n",
        "        est_labels_orig = torch.argmax(model(dataset[m:M, :, :, :]), axis=1)\n",
        "        est_labels_pert = torch.argmax(model(dataset_perturbed[m:M, :, :, :]), axis=1)\n",
        "        \n",
        "        fooling_rate += torch.sum(est_labels_pert != est_labels_orig).item()\n",
        "\n",
        "    # Compute the fooling rate\n",
        "    fooling_rate = fooling_rate / float(num_images)\n",
        "    print('FOOLING RATE = ', fooling_rate)\n",
        "\n",
        "    if fooling_rate < foolrate_prev:\n",
        "      v = v_prev\n",
        "      fooling_rate = foolrate_prev\n",
        "\n",
        "  return v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjMKRZQMILn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def univ_fool_rate(model, device, dataset, v, batch_size=250):\n",
        "    \n",
        "    model = model.to(device).eval()\n",
        "    dataset = dataset.to(device)\n",
        "\n",
        "    num_images = dataset.size(0)\n",
        "    \n",
        "    # Perturb the dataset with the universal perturbation v\n",
        "    dataset_perturbed = (dataset + v).to(device)\n",
        "\n",
        "    num_batches = np.int(np.ceil(np.float(num_images) / np.float(batch_size)))\n",
        "    fooling_rate = 0.0\n",
        "\n",
        "    # Compute the estimated labels in batches\n",
        "    for ii in pbar(range(num_batches)):\n",
        "        m = (ii * batch_size)\n",
        "        M = min((ii+1)*batch_size, num_images)\n",
        "\n",
        "        est_labels_orig = torch.argmax(model(dataset[m:M, :, :, :]), axis=1)\n",
        "        est_labels_pert = torch.argmax(model(dataset_perturbed[m:M, :, :, :]), axis=1)\n",
        "        \n",
        "        fooling_rate += torch.sum(est_labels_pert != est_labels_orig).item()\n",
        "\n",
        "    # Compute the fooling rate\n",
        "    fooling_rate = fooling_rate / float(num_images)\n",
        "    return fooling_rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CU4A8L3KmqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_method(model, device, img, label, method, params):\n",
        "\n",
        "  img = img.clone()\n",
        "\n",
        "  model = model.to(device).eval()\n",
        "\n",
        "  x = img.to(device)\n",
        "  label = label.to(device)\n",
        "\n",
        "  if method in ['fgsm', 'deepfool', 'sparsefool']:\n",
        "    x.requires_grad = True\n",
        "\n",
        "  y = model(x)\n",
        "  init_pred = y.max(1, keepdim=True)[1]\n",
        "  x_conf = F.softmax(y, dim=1).max(1, keepdim=True)[0].item()  \n",
        "\n",
        "  if init_pred.item() != label.item():\n",
        "    print(\"Wrong classification...\")\n",
        "    return\n",
        "\n",
        "  # Call method\n",
        "  if method == 'fgsm':\n",
        "    adv_x, pert_x = fgsm(model, x, label, y, params[\"epsilon\"], params[\"clip\"])\n",
        "\n",
        "  elif method == 'deepfool':\n",
        "    _, adv_x, pert_x, n_iter = deepfool(model, device, x, params[\"num_classes\"], overshoot=params[\"overshoot\"], max_iter=params[\"max_iter\"], p=params[\"p\"], clip=params[\"clip\"])\n",
        "\n",
        "  elif method == 'sparsefool':\n",
        "    # Generate lower and upper bounds\n",
        "    delta = params[\"delta\"]\n",
        "    lb, ub =  valid_bounds(x, delta, dataset='cifar10')\n",
        "    lb = lb[None, :, :, :].to(device)\n",
        "    ub = ub[None, :, :, :].to(device)\n",
        "    adv_x, pert_x, n_iter = sparsefool(model, device, x, label.item(), lb, ub, params[\"lambda_\"], params[\"max_iter\"], params[\"epsilon\"])\n",
        "\n",
        "  elif method == 'one_pixel_attack':\n",
        "    adv_x, n_iter, scores = one_pixel_attack(model, device, x, label.item(), params[\"dim\"], params[\"target_label\"], params[\"iters\"], params[\"pop_size\"], params[\"verbose\"])\n",
        "    pert_x = adv_x - x\n",
        "\n",
        "  y_adv = model(adv_x)\n",
        "  adv_pred = y_adv.max(1, keepdim=True)[1]\n",
        "  adv_x_conf = F.softmax(y_adv, dim=1).max(1, keepdim=True)[0].item()  \n",
        "\n",
        "  if adv_pred.item() == label.item():\n",
        "    print(\"Attack failed...\")\n",
        "\n",
        "  else:\n",
        "    print(\"Succesful attack!\")\n",
        "\n",
        "  f = plt.figure()\n",
        "  f.add_subplot(1,3,1)\n",
        "  plt.title('Original image')\n",
        "  plt.axis('off')\n",
        "  f.text(.25, .3, cifar10_classes[label.item()] + ' ({:.2f}%)'.format(x_conf*100), ha='center')\n",
        "  plt.imshow(displayable(img))\n",
        "  f.add_subplot(1,3,2)\n",
        "  plt.title('Perturbation')\n",
        "  plt.axis('off')\n",
        "  plt.imshow(displayable(pert_x.cpu().detach()))\n",
        "  f.add_subplot(1,3,3)\n",
        "  plt.title('Adv. image')\n",
        "  plt.axis('off')\n",
        "  f.text(.8, .3, cifar10_classes[adv_pred.item()] + ' ({:.2f}%)'.format(adv_x_conf*100), ha='center')\n",
        "  plt.imshow(displayable(adv_x.cpu().detach()))\n",
        "  plt.show(block=True)\n",
        "\n",
        "  if method in ['deepfool',  'sparsefool', 'one_pixel_attack']:\n",
        "    print('Number of iterations needed: ', n_iter)\n",
        "\n",
        "  if method == 'sparsefool':\n",
        "    pert_pixels = pert_x.flatten().nonzero().size(0)\n",
        "    print('Number of perturbed pixels: ', pert_pixels) \n",
        "\n",
        "  if method == 'one_pixel_attack':\n",
        "    return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zxW6hZmQfyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attack_model(model, device, test_loader, method, params, p=2, iters=10000, dataset='cifar10'):\n",
        "\n",
        "  # Initialize the network and set the model in evaluation mode.\n",
        "  model = model.to(device).eval()\n",
        "\n",
        "  # Initialize stat counters\n",
        "  correct = 0\n",
        "  incorrect = 0\n",
        "  confidence = 0\n",
        "  total_time = 0\n",
        "  ex_robustness = 0\n",
        "  model_robustness = 0\n",
        "  method_iters = 0\n",
        "  n_pert_pixels = []\n",
        "  adv_examples = []\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  # Loop (iters) examples in test set\n",
        "  for data, target in pbar(test_loader):\n",
        "    if i >= iters:\n",
        "      break\n",
        "    i += 1\n",
        "\n",
        "    # Send the data and label to the device\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Set requires_grad attribute of tensor (important for some attacks)\n",
        "    if method in ['fgsm', 'deepfool', 'sparsefool']:\n",
        "        data.requires_grad = True\n",
        "\n",
        "    # Forward pass the data through the model\n",
        "    output = model(data)\n",
        "    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "    # If the initial prediction is wrong, dont botter attacking\n",
        "    if init_pred.item() != target.item():\n",
        "      continue\n",
        "\n",
        "    if method == 'fgsm':\n",
        "        # Call FGSM attack\n",
        "        time_ini = time.time()\n",
        "        perturbed_data, _ = fgsm(model, data, target, output, params[\"epsilon\"], params[\"clip\"], dataset)\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "\n",
        "    elif method == 'deepfool':\n",
        "        # Call DeepFool attack\n",
        "        time_ini = time.time()\n",
        "        _, perturbed_data, _, n_iter = deepfool(model, device, data, params[\"num_classes\"], overshoot=params[\"overshoot\"], max_iter=params[\"max_iter\"], p=params[\"p\"], clip=params[\"clip\"])\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "        method_iters += n_iter\n",
        "\n",
        "    elif method == 'sparsefool':\n",
        "        # Generate lower and upper bounds\n",
        "        delta = params[\"delta\"]\n",
        "        lb, ub =  valid_bounds(data, delta, dataset='cifar10')\n",
        "        lb = lb[None, :, :, :].to(device)\n",
        "        ub = ub[None, :, :, :].to(device)\n",
        "        # Call SparseFool attack\n",
        "        time_ini = time.time()\n",
        "        perturbed_data, perturbation, n_iter = sparsefool(model, device, data, target.item(), lb, ub, params[\"lambda_\"], params[\"max_iter\"], params[\"epsilon\"])\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "        method_iters += n_iter\n",
        "        n_pert_pixels.append(perturbation.flatten().nonzero().size(0))\n",
        "\n",
        "    elif method == 'one_pixel_attack':\n",
        "        # Call one pixel attack\n",
        "        time_ini = time.time()\n",
        "        perturbed_data, n_iter, _ = one_pixel_attack(model, device, data, target.item(), params[\"dim\"], params[\"target_label\"], params[\"iters\"], params[\"pop_size\"], params[\"verbose\"])\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "        method_iters += n_iter\n",
        "\n",
        "\n",
        "    # Update model robustness\n",
        "    # multiply by std to make it independent of the normalization used\n",
        "    difference = de_scale(perturbed_data-data, dataset)\n",
        "    if p == 2:\n",
        "      adv_rob = torch.norm(difference)  # Frobenius norm (p=2)\n",
        "      model_robustness += adv_rob / torch.norm(de_scale(data, dataset))\n",
        "    elif p == np.inf:\n",
        "      adv_rob = torch.norm(difference, float('inf'))  # Inf norm (p=inf)\n",
        "      model_robustness += adv_rob / torch.norm(de_scale(data, dataset), float('inf'))\n",
        "    ex_robustness += adv_rob\n",
        "    \n",
        "    # Re-classify the perturbed image\n",
        "    output = model(perturbed_data)\n",
        "\n",
        "    # Check for success\n",
        "    final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "    \n",
        "    if final_pred.item() == target.item():\n",
        "      correct += 1\n",
        "    \n",
        "    else:\n",
        "      incorrect += 1\n",
        "      # Update average confidence\n",
        "      confidence += F.softmax(output, dim=1).max(1, keepdim=True)[0].item()  \n",
        "      # Save some adv examples for visualization later\n",
        "      if len(adv_examples) < 5:\n",
        "        adv_examples.append( (init_pred.item(), final_pred.item(), data.detach().cpu(), perturbed_data.detach().cpu()) )\n",
        "\n",
        "  # Calculate stats\n",
        "  final_acc = correct / float(iters)  # len(test_loader)\n",
        "  avg_confidence = confidence / float(incorrect)\n",
        "  avg_time = total_time / float(correct+incorrect)\n",
        "  avg_ex_robustness = ex_robustness / float(correct+incorrect)\n",
        "  model_robustness = model_robustness / float(correct+incorrect)\n",
        "  print(\"\\n======== RESULTS ========\")\n",
        "  print(\"Test Accuracy = {} / {} = {:.4f}\\nAverage confidence = {:.4f}\\nAverage time = {:.4f}\\nAverage magnitude of perturbations = {:.4f}\\nModel robustness = {:.4f}\"\n",
        "    .format(correct, iters, final_acc, avg_confidence, avg_time, avg_ex_robustness, model_robustness))\n",
        "\n",
        "  if method in ['deepfool', 'sparsefool', 'one_pixel_attack']:\n",
        "    print(\"Avg. iters = {:.2f}\".format(method_iters / float(correct+incorrect)))\n",
        "\n",
        "  if method == 'sparsefool':\n",
        "    print(\"Median num. of pixels perturbed = \", statistics.median(n_pert_pixels))\n",
        "    print(\"Average num. of pixels perturbed = {:.2f}\".format(statistics.mean(n_pert_pixels)))\n",
        "\n",
        "  # Return adversarial examples\n",
        "  return adv_examples"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}