{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_experiments.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMKMrG899IW3WM8Zvnt9TAC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pabloac31/TFG/blob/master/cifar10_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZIrtm8vDL9s",
        "colab_type": "text"
      },
      "source": [
        "**Clone the repository**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6ctRAXTcHH2",
        "colab_type": "code",
        "outputId": "ad80c5a0-aa76-4106-d35e-d16fbd164be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "! git clone https://github.com/pabloac31/TFG.git\n",
        "%cd TFG"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'TFG'\n",
            "/content/TFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmR1_uT1ELeN",
        "colab_type": "text"
      },
      "source": [
        "**Using Tensorflow v1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1YD-wgycX9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wThIjzaBEWab",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Qs_zdCcZS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cifar10_models import *\n",
        "from utils import *\n",
        "from adversarial_attacks import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7h0dj4BE-U7",
        "colab_type": "text"
      },
      "source": [
        "**Load models pretrained on CIFAR10**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq7UhHCkcpW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet = resnet50(pretrained=True)\n",
        "densenet = densenet169(pretrained=True)\n",
        "mobnet = mobilenet_v2(pretrained=True)\n",
        "iv3 = inception_v3(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFqYGnBSFMxL",
        "colab_type": "text"
      },
      "source": [
        "**Use CUDA if available for faster results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ugar45Fcrmo",
        "colab_type": "code",
        "outputId": "c83743ad-5e36-4811-ec8a-81793f19868b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "use_cuda=True\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eLXv5lbGHwx",
        "colab_type": "text"
      },
      "source": [
        "**Create dataloaders**\n",
        "\n",
        "Load CIFAR10 test images as tensors of size NxCxHxW normalized with CIFAR10 mean and std."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8pZ6UNBctah",
        "colab_type": "code",
        "outputId": "1a3650c8-8a39-4fc4-d02d-cfb7badcd546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "test_loader = testloader_cifar10('./data', batch_size=256, shuffle=False)  # Dataloader for testing the model \n",
        "adv_loader = testloader_cifar10('./data', batch_size=1)                    # Dataloader for adversarial attacks\n",
        "univ_loader = testloader_cifar10('./data', batch_size=1, shuffle=False)    # Dataloader for universal attack"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HMLdKZWGvKt",
        "colab_type": "text"
      },
      "source": [
        "**Test models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JwdTaCecvpK",
        "colab_type": "code",
        "outputId": "a83b02e1-d53f-4295-d8f6-d980dda02480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "acc = test_model(mobnet, device, test_loader)\n",
        "print('\\nAccuracy on CIFAR10 test set: ', acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:03<00:00, 10.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy on CIFAR10 test set:  0.9299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5-jN371fV32",
        "colab_type": "text"
      },
      "source": [
        "**Set method parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVW-1y_PfhF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_fgsm = {'epsilon': 0.01, 'clip': True}\n",
        "params_deepfool1 = {'num_classes': 10, 'overshoot': 0.01, 'max_iter': 50, 'clip': True}\n",
        "params_deepfool2 = {'num_classes': 10, 'overshoot': 0.01, 'max_iter': 50, 'clip': False}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4ipPW1fexSV",
        "colab_type": "text"
      },
      "source": [
        "**Test methods**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHUn30pJcyPK",
        "colab_type": "code",
        "outputId": "8464b2dd-1829-431b-d352-6f8cb643f89c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "image, label = next(iter(adv_loader))\n",
        "test_method(mobnet, device, image, label, method='deepfool', params=params_deepfool1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Succesful attack!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Number of iterations needed:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiUyFraoe-Xh",
        "colab_type": "text"
      },
      "source": [
        "**Perform a complete attack and show results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHSVmm2dc0NZ",
        "colab_type": "code",
        "outputId": "82d83da2-fb90-4394-d981-f9b8c5c6d74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "#params = {'lambda_': 3., 'max_iter': 20, 'epsilon': 0.2, 'delta': 255}\n",
        "#params = {'target_label': None, 'iters': 10, 'pop_size': 100, 'verbose': True}\n",
        "\n",
        "adv_examples = attack_model(mobnet, device, adv_loader, 'deepfool', params_deepfool1)\n",
        "\n",
        "adv_examples = attack_model(mobnet, device, adv_loader, 'deepfool', params_deepfool2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [27:27<00:00,  6.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== RESULTS ========\n",
            "Test Accuracy = 356 / 10000 = 0.0356\n",
            "Average confidence = 0.6825\n",
            "Average time = 0.1602\n",
            "Average magnitude of perturbations = 4.5759\n",
            "Model robustness = 0.3602\n",
            "Avg. iters = 1.45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [28:16<00:00,  5.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== RESULTS ========\n",
            "Test Accuracy = 0 / 10000 = 0.0000\n",
            "Average confidence = 0.6452\n",
            "Average time = 0.1647\n",
            "Average magnitude of perturbations = 9.0890\n",
            "Model robustness = 0.7110\n",
            "Avg. iters = 1.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xseEdeDnHlGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v = universal_perturbation(univ_loader, iv3, device, delta=0.1)\n",
        "\n",
        "plt.imshow(denormalize_cifar10(v[0].cpu().detach().numpy()).transpose((1,2,0)))\n",
        "plt.title('Universal perturbation')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTnsNwRMmxWt",
        "colab_type": "code",
        "outputId": "de85220c-075a-412b-9379-2359bd7132c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "image = Image.open('./data/img1.png')\n",
        "x = TF.to_tensor(image)\n",
        "x = normalize_cifar10(x)\n",
        "x = x.unsqueeze_(0).to(device)\n",
        "label = torch.tensor([1]).to(device)\n",
        "print('Label:', label.item())\n",
        "x.requires_grad = True\n",
        "y = iv3(x)\n",
        "init_pred = y.max(1, keepdim=True)[1]\n",
        "print(\"Original image prediction: \", init_pred.item())\n",
        "x_r = x.add(v).to(device)\n",
        "pred = iv3(x_r).max(1, keepdim=True)[1]\n",
        "print(\"Perturbed image prediction: \", pred.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 1\n",
            "Original image prediction:  1\n",
            "Perturbed image prediction:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoSdwQ1ne1mA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img, label = next(iter(adv_loader))\n",
        "im = denormalize_cifar10(img.numpy()[0].copy()).transpose((1,2,0))\n",
        "plt.imshow(im)\n",
        "plt.show()\n",
        "label = label.item()\n",
        "success, sol, score = one_pixel_attack(iv3, device, img, label, pop_size=400, iters=20)\n",
        "print(success)\n",
        "print(score)\n",
        "adv = perturb(sol, img)\n",
        "im = denormalize_cifar10(adv.numpy()[0].copy()).transpose((1,2,0))\n",
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zxW6hZmQfyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attack_model(model, device, test_loader, method, params, iters=10000, dataset='cifar10'):\n",
        "\n",
        "  # Initialize the network and set the model in evaluation mode.\n",
        "  model = model.to(device).eval()\n",
        "\n",
        "  # Initialize stat counters\n",
        "  correct = 0\n",
        "  incorrect = 0\n",
        "  confidence = 0\n",
        "  total_time = 0\n",
        "  ex_robustness = 0\n",
        "  model_robustness = 0\n",
        "  method_iters = 0\n",
        "  adv_examples = []\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  # Loop (iters) examples in test set\n",
        "  for data, target in pbar(test_loader):\n",
        "    if i >= iters:\n",
        "      break\n",
        "    i += 1\n",
        "\n",
        "    # Send the data and label to the device\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Set requires_grad attribute of tensor (important for some attacks)\n",
        "    if method in ['fgsm', 'deepfool', 'sparsefool']:\n",
        "        data.requires_grad = True\n",
        "\n",
        "    # Forward pass the data through the model\n",
        "    output = model(data)\n",
        "    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "    # If the initial prediction is wrong, dont botter attacking\n",
        "    if init_pred.item() != target.item():\n",
        "      continue\n",
        "\n",
        "    if method == 'fgsm':\n",
        "        # Call FGSM attack\n",
        "        time_ini = time.time()\n",
        "        perturbed_data, _ = fgsm(model, data, target, output, params[\"epsilon\"], params[\"clip\"], dataset)\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "\n",
        "    elif method == 'deepfool':\n",
        "        # Call DeepFool attack\n",
        "        time_ini = time.time()\n",
        "        _, perturbed_data, _, n_iter = deepfool(model, device, data, params[\"num_classes\"], params[\"overshoot\"], params[\"max_iter\"], params[\"clip\"])\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "        method_iters += n_iter\n",
        "\n",
        "    elif method == 'sparsefool':\n",
        "        # Generate lower and upper bounds\n",
        "        delta = params[\"delta\"]\n",
        "        lb, ub =  valid_bounds_cifar10(data, delta)\n",
        "        lb = lb[None, :, :, :].to(device)\n",
        "        ub = ub[None, :, :, :].to(device)\n",
        "        # Call SparseFool attack\n",
        "        time_ini = time.time()\n",
        "        perturbed_data = sparsefool(model, device, data, target.item(), lb, ub, params[\"lambda_\"], params[\"max_iter\"], params[\"epsilon\"])\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "\n",
        "    elif method == 'one_pixel_attack':\n",
        "        # Call one pixel attack\n",
        "        time_ini = time.time()\n",
        "        _, best_sol, score = one_pixel_attack(model, device, data, target.item(), params[\"target_label\"], params[\"iters\"], params[\"pop_size\"], params[\"verbose\"])\n",
        "        perturbed_data = perturb(best_sol, data)\n",
        "        time_end = time.time()\n",
        "        total_time += time_end-time_ini\n",
        "\n",
        "\n",
        "    # Update model robustness\n",
        "    # multiply by std to make it independent of the normalization used\n",
        "    difference = de_scale(perturbed_data-data, dataset)\n",
        "    adv_rob = torch.norm(difference)  # Frobenius norm (p=2)\n",
        "    #adv_rov = torch.norm(difference, float('inf'))  # Inf norm (p=inf)\n",
        "    ex_robustness += adv_rob\n",
        "    model_robustness += adv_rob / torch.norm(de_scale(data, dataset))\n",
        "    #model_robustness += adv_rob / torch.norm(de_scale(data, dataset), float('inf'))\n",
        "\n",
        "    # Re-classify the perturbed image\n",
        "    output = model(perturbed_data)\n",
        "\n",
        "    # Check for success\n",
        "    final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "    \n",
        "    if final_pred.item() == target.item():\n",
        "      correct += 1\n",
        "    \n",
        "    else:\n",
        "      incorrect += 1\n",
        "      # Update average confidence\n",
        "      confidence += F.softmax(output, dim=1).max(1, keepdim=True)[0].item()  \n",
        "      # Save some adv examples for visualization later\n",
        "      if len(adv_examples) < 5:\n",
        "        adv_examples.append( (init_pred.item(), final_pred.item(), data.detach().cpu(), perturbed_data.detach().cpu()) )\n",
        "\n",
        "  # Calculate stats\n",
        "  final_acc = correct / float(iters)  # len(test_loader)\n",
        "  avg_confidence = confidence / float(incorrect)\n",
        "  avg_time = total_time / float(correct+incorrect)\n",
        "  avg_ex_robustness = ex_robustness / float(correct+incorrect)\n",
        "  model_robustness = model_robustness / float(correct+incorrect)\n",
        "  print(\"\\n======== RESULTS ========\")\n",
        "  print(\"Test Accuracy = {} / {} = {:.4f}\\nAverage confidence = {:.4f}\\nAverage time = {:.4f}\\nAverage magnitude of perturbations = {:.4f}\\nModel robustness = {:.4f}\"\n",
        "    .format(correct, iters, final_acc, avg_confidence, avg_time, avg_ex_robustness, model_robustness))\n",
        "\n",
        "  if method == 'deepfool':\n",
        "    print(\"Avg. iters = {:.2f}\".format(method_iters / float(correct+incorrect)))\n",
        "\n",
        "  # Return adversarial examples\n",
        "  return adv_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CU4A8L3KmqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_method(model, device, img, label, method, params):\n",
        "\n",
        "  model = model.to(device).eval()\n",
        "\n",
        "  x = img.to(device)\n",
        "  label = label.to(device)\n",
        "\n",
        "  x.requires_grad = True\n",
        "\n",
        "  y = model(x)\n",
        "  init_pred = y.max(1, keepdim=True)[1]\n",
        "\n",
        "  if init_pred.item() != label.item():\n",
        "    print(\"Wrong classification...\")\n",
        "    return\n",
        "\n",
        "  # Call method\n",
        "  if method == 'fgsm':\n",
        "    adv_x, pert_x = fgsm(model, x, label, y, params[\"epsilon\"], params[\"clip\"])\n",
        "\n",
        "  elif method == 'deepfool':\n",
        "    _, adv_x, pert_x, n_iter = deepfool(model, device, x, params[\"num_classes\"], params[\"overshoot\"], params[\"max_iter\"], params[\"clip\"])\n",
        "\n",
        "  elif method == 'sparsefool':\n",
        "    # Generate lower and upper bounds\n",
        "    delta = params[\"delta\"]\n",
        "    lb, ub =  valid_bounds_cifar10(data, delta)\n",
        "    lb = lb[None, :, :, :].to(device)\n",
        "    ub = ub[None, :, :, :].to(device)\n",
        "    adv_x = sparsefool(model, device, data, target.item(), lb, ub, params[\"lambda_\"], params[\"max_iter\"], params[\"epsilon\"])\n",
        "\n",
        "  elif method == 'one_pixel_attack':\n",
        "    _, best_sol, score = one_pixel_attack(model, device, data, target.item(), params[\"target_label\"], params[\"iters\"], params[\"pop_size\"], params[\"verbose\"])\n",
        "    adv_x = perturb(best_sol, data)\n",
        "\n",
        "  y_adv = model(adv_x)\n",
        "  adv_pred = y_adv.max(1, keepdim=True)[1]\n",
        "\n",
        "  if adv_pred.item() == label.item():\n",
        "    print(\"Attack failed...\")\n",
        "\n",
        "  else:\n",
        "    print(\"Succesful attack!\")\n",
        "\n",
        "  f = plt.figure()\n",
        "  f.add_subplot(1,3,1)\n",
        "  plt.title('Original image -> ' + str(label.item()))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(displayable(img))\n",
        "  f.add_subplot(1,3,2)\n",
        "  plt.title('Perturbation')\n",
        "  plt.axis('off')\n",
        "  plt.imshow(displayable(pert_x.cpu().detach()))\n",
        "  f.add_subplot(1,3,3)\n",
        "  plt.title('Adv. image -> ' + str(adv_pred.item()))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(displayable(adv_x.cpu().detach()))\n",
        "  plt.show(block=True)\n",
        "\n",
        "  if method == 'deepfool':\n",
        "    print('Number of iterations needed: ', n_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYiOdOohf_cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deepfool(model, device, image, num_classes=10, overshoot=0.02, max_iter=50, clip=False, dataset='cifar10'):\n",
        "\n",
        "  # Get the output of the original image\n",
        "  output = model(image)\n",
        "  # Get the input image shape\n",
        "  input_shape = image.size()\n",
        "  # Array with the class probabilities of the image\n",
        "  f_image = output.data.cpu().numpy().flatten()\n",
        "  # Classes ordered by probability (descending)\n",
        "  I = f_image.argsort()[::-1]\n",
        "  # We consider only 'num_classes' classes\n",
        "  I = I[0:num_classes]\n",
        "  # Get the predicted label\n",
        "  label = I[0]\n",
        "\n",
        "  # Start from a copy of the original image\n",
        "  pert_image = copy.deepcopy(image)   # tensor of size (1,3,H,W)\n",
        "\n",
        "  # Initialize variables\n",
        "  r_tot = torch.zeros(input_shape).to(device) # adversarial perturbation\n",
        "  k_i = label  # current label\n",
        "  loop_i = 0\n",
        "\n",
        "  while k_i == label and loop_i < max_iter:\n",
        "\n",
        "    # Get the output for the current image\n",
        "    x = pert_image.clone().detach().requires_grad_(True)\n",
        "    fs = model(x)\n",
        "\n",
        "    pert = torch.Tensor([np.inf])[0].to(device)\n",
        "    w = torch.zeros(input_shape).to(device)\n",
        "\n",
        "    # Calculate grad(f_label(x_i))\n",
        "    fs[0, I[0]].backward(retain_graph=True)\n",
        "    grad_orig = grad_orig = copy.deepcopy(x.grad.data)\n",
        "\n",
        "    for k in range(1, num_classes):  # for k != label\n",
        "      # Reset gradients\n",
        "      zero_gradients(x)\n",
        "\n",
        "      # Calculate grad(f_k(x_i))\n",
        "      fs[0, I[k]].backward(retain_graph=True)\n",
        "      cur_grad = copy.deepcopy(x.grad.data)\n",
        "\n",
        "      # Set new w_k and new f_k\n",
        "      w_k = cur_grad - grad_orig\n",
        "      f_k = (fs[0, I[k]] - fs[0, I[0]]).data\n",
        "\n",
        "      # Calculate hyperplane-k distance\n",
        "      pert_k = torch.abs(f_k) / w_k.norm()  # Frobenious norm (2-norm)\n",
        "\n",
        "      # determine which w_k to use\n",
        "      if pert_k < pert:\n",
        "        pert = pert_k + 0.\n",
        "        w = w_k + 0.\n",
        "\n",
        "    # compute r_i and r_tot\n",
        "    r_i = torch.clamp(pert, min=1e-4) * w / w.norm()  # Added 1e-4 for numerical stability\n",
        "    r_tot = r_tot + r_i\n",
        "\n",
        "    # Update perturbed image\n",
        "    pert_image = pert_image + r_i  # x_(i+1) <- x_i + r_i\n",
        "\n",
        "    # Adding overshoot\n",
        "    check_fool = image + (1 + overshoot) * r_tot\n",
        "\n",
        "    x = check_fool.clone().detach().requires_grad_(True)\n",
        "    # output for x_(i+1)\n",
        "    fs = model(x)\n",
        "    # label assigned to x_(i+1)\n",
        "    k_i = torch.argmax(fs.data).item()\n",
        "\n",
        "    loop_i += 1\n",
        "\n",
        "  # Compute final perturbed image output\n",
        "  x = pert_image.clone().detach().requires_grad_(True)\n",
        "  fs = model(x)\n",
        "  # Compute final gradient\n",
        "  (fs[0, k_i] - fs[0, label]).backward(retain_graph=True)\n",
        "  grad = copy.deepcopy(x.grad.data)\n",
        "  grad = grad / grad.norm()\n",
        "\n",
        "  # Include overshoot in the adversarial perturbation\n",
        "  r_tot = (1 + overshoot) * r_tot\n",
        "\n",
        "  # Update adverarial image (pert_image = image + r_tot)\n",
        "  #p_im = image.detach().cpu().numpy() + r_tot.detach().cpu().numpy() # for deepcopy\n",
        "  #pert_image = torch.from_numpy(p_im).to(device)\n",
        "\n",
        "  # Adding clipping to maintain [0,1] range\n",
        "  if clip:\n",
        "    pert_image = clamp(image + r_tot, 0, 1, dataset)\n",
        "\n",
        "  else:\n",
        "    pert_image = image + r_tot\n",
        "\n",
        "  return grad, pert_image, r_tot, loop_i"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}